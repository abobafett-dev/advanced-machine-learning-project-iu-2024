{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "          ItemID  Sentiment SentimentSource  \\\n11437      11449          0    Sentiment140   \n93376      93388          0    Sentiment140   \n190914    190926          1    Sentiment140   \n324696    324708          1    Sentiment140   \n327276    327288          1    Sentiment140   \n482519    482531          1    Sentiment140   \n562651    562665          1    Sentiment140   \n661792    661806          0    Sentiment140   \n770212    770226          1    Sentiment140   \n907223    907237          1    Sentiment140   \n1155122  1155136          1    Sentiment140   \n1160897  1160911          1    Sentiment140   \n1164325  1164339          0    Sentiment140   \n1397203  1397217          1    Sentiment140   \n1415815  1415829          1    Sentiment140   \n1456956  1456970          1    Sentiment140   \n\n                                             SentimentText  \n11437    #squarespace not many days left  iwanna iphone...  \n93376              @christinaomgz i know gurll /I did too   \n190914             @essteeyou bangin, i got /o that rocks   \n324696   @moniquemassacre i still loves you!!! /d i kno...  \n327276   @MossyBlog good luck  could try fdisk /mbr  or...  \n482519   @sd2kslay does that mean ur back? /g invite if...  \n562651   @30STMluva Come, break me down/ bury me, bury ...  \n661792   Dying in the heat! Bought a new energy saving ...  \n770212   http://tr.im/jd41 Soooooo cool! I love these S...  \n907223                         is at home chilling /w fam   \n1155122  pilot to co-pilot baby we burnin' up   /i cann...  \n1160897  Spent yesterday outside painting wood for the ...  \n1164325  psyched about the evolver con call. real inter...  \n1397203  Eh. G'morning muthafuckers! Ugh. ~mm only piss...  \n1415815  great day, had brunch /w friends and then socc...  \n1456956  I'm being lazy this morning &amp; what's a fun...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>Sentiment</th>\n      <th>SentimentSource</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11437</th>\n      <td>11449</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>#squarespace not many days left  iwanna iphone...</td>\n    </tr>\n    <tr>\n      <th>93376</th>\n      <td>93388</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>@christinaomgz i know gurll /I did too</td>\n    </tr>\n    <tr>\n      <th>190914</th>\n      <td>190926</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>@essteeyou bangin, i got /o that rocks</td>\n    </tr>\n    <tr>\n      <th>324696</th>\n      <td>324708</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>@moniquemassacre i still loves you!!! /d i kno...</td>\n    </tr>\n    <tr>\n      <th>327276</th>\n      <td>327288</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>@MossyBlog good luck  could try fdisk /mbr  or...</td>\n    </tr>\n    <tr>\n      <th>482519</th>\n      <td>482531</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>@sd2kslay does that mean ur back? /g invite if...</td>\n    </tr>\n    <tr>\n      <th>562651</th>\n      <td>562665</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>@30STMluva Come, break me down/ bury me, bury ...</td>\n    </tr>\n    <tr>\n      <th>661792</th>\n      <td>661806</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>Dying in the heat! Bought a new energy saving ...</td>\n    </tr>\n    <tr>\n      <th>770212</th>\n      <td>770226</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>http://tr.im/jd41 Soooooo cool! I love these S...</td>\n    </tr>\n    <tr>\n      <th>907223</th>\n      <td>907237</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>is at home chilling /w fam</td>\n    </tr>\n    <tr>\n      <th>1155122</th>\n      <td>1155136</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>pilot to co-pilot baby we burnin' up   /i cann...</td>\n    </tr>\n    <tr>\n      <th>1160897</th>\n      <td>1160911</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>Spent yesterday outside painting wood for the ...</td>\n    </tr>\n    <tr>\n      <th>1164325</th>\n      <td>1164339</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>psyched about the evolver con call. real inter...</td>\n    </tr>\n    <tr>\n      <th>1397203</th>\n      <td>1397217</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>Eh. G'morning muthafuckers! Ugh. ~mm only piss...</td>\n    </tr>\n    <tr>\n      <th>1415815</th>\n      <td>1415829</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>great day, had brunch /w friends and then socc...</td>\n    </tr>\n    <tr>\n      <th>1456956</th>\n      <td>1456970</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>I'm being lazy this morning &amp;amp; what's a fun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_path = '../datasets/Sentiment-Analysis-Dataset.zip'\n",
    "\n",
    "extraction_path = '../datasets/'\n",
    "\n",
    "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "extracted_files = os.listdir(extraction_path)\n",
    "\n",
    "csv_file_path = os.path.join(extraction_path, 'Sentiment Analysis Dataset.csv')\n",
    "df = pd.read_csv(csv_file_path, usecols=['ItemID', 'Sentiment', 'SentimentSource', 'SentimentText'])\n",
    "\n",
    "messages = df['SentimentText']\n",
    "\n",
    "regex_pattern = '\\s\\/[a-zA-Z]\\s'\n",
    "filtered_df = df[df['SentimentText'].str.contains(regex_pattern)]\n",
    "\n",
    "print(filtered_df.shape)\n",
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": "              user_name        user_location  \\\n123808  Megan Thackeray  North West, England   \n\n                                         user_description  \\\n123808  Assistant Psychologist working in neuro - ABI....   \n\n               user_created  user_followers  user_friends  user_favourites  \\\n123808  2017-05-29 23:08:51              27            65              151   \n\n        user_verified                 date  \\\n123808          False  2020-08-13 07:31:36   \n\n                                                     text     hashtags  \\\n123808  Yet another thing to be proud of Oldham for. ü§¶...  ['COVID19']   \n\n                     source  is_retweet  \n123808  Twitter for Android       False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_name</th>\n      <th>user_location</th>\n      <th>user_description</th>\n      <th>user_created</th>\n      <th>user_followers</th>\n      <th>user_friends</th>\n      <th>user_favourites</th>\n      <th>user_verified</th>\n      <th>date</th>\n      <th>text</th>\n      <th>hashtags</th>\n      <th>source</th>\n      <th>is_retweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>123808</th>\n      <td>Megan Thackeray</td>\n      <td>North West, England</td>\n      <td>Assistant Psychologist working in neuro - ABI....</td>\n      <td>2017-05-29 23:08:51</td>\n      <td>27</td>\n      <td>65</td>\n      <td>151</td>\n      <td>False</td>\n      <td>2020-08-13 07:31:36</td>\n      <td>Yet another thing to be proud of Oldham for. ü§¶...</td>\n      <td>['COVID19']</td>\n      <td>Twitter for Android</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_path = '../datasets/archive.zip'\n",
    "\n",
    "extraction_path = '../datasets/'\n",
    "\n",
    "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "csv_file_path = os.path.join(extraction_path, 'covid19_tweets.csv')\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "regex_pattern = '\\s\\/[a-zA-Z]\\s'\n",
    "filtered_df = df[df['text'].str.contains(regex_pattern)]\n",
    "\n",
    "print(filtered_df.shape)\n",
    "filtered_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_emotions = load_dataset(\"go_emotions\", \"raw\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear', 'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'],\n        num_rows: 211225\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_emotions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'That game hurt.', 'id': 'eew5j0j', 'author': 'Brdd9', 'subreddit': 'nrl', 'link_id': 't3_ajis4z', 'parent_id': 't1_eew18eq', 'created_utc': 1548381056.0, 'rater_id': 1, 'example_very_unclear': False, 'admiration': 0, 'amusement': 0, 'anger': 0, 'annoyance': 0, 'approval': 0, 'caring': 0, 'confusion': 0, 'curiosity': 0, 'desire': 0, 'disappointment': 0, 'disapproval': 0, 'disgust': 0, 'embarrassment': 0, 'excitement': 0, 'fear': 0, 'gratitude': 0, 'grief': 0, 'joy': 0, 'love': 0, 'nervousness': 0, 'optimism': 0, 'pride': 0, 'realization': 0, 'relief': 0, 'remorse': 0, 'sadness': 1, 'surprise': 0, 'neutral': 0}\n"
     ]
    }
   ],
   "source": [
    "for raw in dataset_emotions['train']:\n",
    "    print(raw)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    'admiration': 0,\n",
    "    'amusement': 0,\n",
    "    'anger': 0,\n",
    "    'annoyance': 0,\n",
    "    'approval': 0,\n",
    "    'caring': 0,\n",
    "    'confusion': 0,\n",
    "    'curiosity': 0,\n",
    "    'desire': 0,\n",
    "    'disappointment': 0,\n",
    "    'disapproval': 0,\n",
    "    'disgust': 0,\n",
    "    'embarrassment': 0,\n",
    "    'excitement': 0,\n",
    "    'fear': 0,\n",
    "    'gratitude': 0,\n",
    "    'grief': 0,\n",
    "    'joy': 0,\n",
    "    'love': 0,\n",
    "    'nervousness': 0,\n",
    "    'optimism': 0,\n",
    "    'pride': 0,\n",
    "    'realization': 0,\n",
    "    'relief': 0,\n",
    "    'remorse': 0,\n",
    "    'sadness': 1,\n",
    "    'surprise': 0,\n",
    "    'neutral': 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "emtions_ru = {\n",
    "    '–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ': 0,\n",
    "    '–Ω–∞ –≤–µ—Å–µ–ª–µ': 0,\n",
    "    '–≥–Ω–µ–≤': 0,\n",
    "    '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ': 0,\n",
    "    '–æ–¥–æ–±—Ä–µ–Ω–∏–µ': 0,\n",
    "    '–∑–∞–±–æ—Ç–∞': 0,\n",
    "    '—Ä–∞—Å—Ç–µ—Ä—è–Ω–Ω–æ—Å—Ç—å': 0,\n",
    "    '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ': 0,\n",
    "    '–∂–µ–ª–∞–Ω–∏–µ': 0,\n",
    "    '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ': 0,\n",
    "    '–Ω–µ–æ–¥–æ–±—Ä–µ–Ω–∏–µ': 0,\n",
    "    '–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ': 0,\n",
    "    '—Å–º—É—â–µ–Ω–∏–µ': 0,\n",
    "    '–≤–æ–ª–Ω–µ–Ω–∏–µ': 0,\n",
    "    '—Å—Ç—Ä–∞—Ö': 0,\n",
    "    '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å': 0,\n",
    "    '–≥–æ—Ä–µ': 0,\n",
    "    '—Ä–∞–¥–æ—Å—Ç—å': 0,\n",
    "    '–ª—é–±–æ–≤—å': 0,\n",
    "    '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å': 0,\n",
    "    '–æ–ø—Ç–∏–º–∏–∑–º': 0,\n",
    "    '–≥–æ—Ä–¥–æ—Å—Ç—å': 0,\n",
    "    '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ': 0,\n",
    "    '–æ–±–ª–µ–≥—á–µ–Ω–∏–µ': 0,\n",
    "    '—Ä–∞—Å–∫–∞—è–Ω–∏–µ': 0,\n",
    "    '–≥—Ä—É—Å—Ç—å': 1,\n",
    "    '—É–¥–∏–≤–ª–µ–Ω–∏–µ': 0,\n",
    "    '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π': 0,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

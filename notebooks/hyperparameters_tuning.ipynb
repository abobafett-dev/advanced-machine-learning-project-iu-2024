{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 8216013,
     "sourceType": "datasetVersion",
     "datasetId": 4816660
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install torchtext\n",
    "is_kaggle = False\n",
    "working_dir = '/kaggle/input/aml-dataset' if is_kaggle else '../datasets'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:38.388309Z",
     "iopub.execute_input": "2024-05-06T00:05:38.388714Z",
     "iopub.status.idle": "2024-05-06T00:05:38.393331Z",
     "shell.execute_reply.started": "2024-05-06T00:05:38.388687Z",
     "shell.execute_reply": "2024-05-06T00:05:38.392314Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:07:57.139394Z",
     "start_time": "2024-05-08T15:07:57.132035Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## Todo:\n- Переписать метрики\n- Перебор hyperparameters\n\n## Пути улучшения\n- Провести эксперименты со всеми датасетами\n- Модификация RNN, LSTM\n- Взять модель с Hugging Face\n- Изменить embedings (larger Glove, twiter glove, trainable glove)\n- Перебор hyperparameters\n    > lr",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"wanb\")\n",
    "secret_value_0 = \"write_your_secret_wandb_key\"\n",
    "secret_value_0 = \"5f908c81529fb55aaa472155b075ca91804dac20\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:42.848927Z",
     "iopub.execute_input": "2024-05-06T00:05:42.849253Z",
     "iopub.status.idle": "2024-05-06T00:05:43.189116Z",
     "shell.execute_reply.started": "2024-05-06T00:05:42.849223Z",
     "shell.execute_reply": "2024-05-06T00:05:43.188149Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:00.967037Z",
     "start_time": "2024-05-08T15:07:57.141394Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: shalagin-danil (my_own_opt). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\89123\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.190344Z",
     "iopub.execute_input": "2024-05-06T00:05:43.190685Z",
     "iopub.status.idle": "2024-05-06T00:05:43.196825Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.190653Z",
     "shell.execute_reply": "2024-05-06T00:05:43.195849Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.315813Z",
     "start_time": "2024-05-08T15:08:00.970036Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "## Text preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def str_to_list(value):\n    list_values = value.strip('[]').split(', ')\n    cleaned_list_values = [item[1:-1] for item in list_values]\n    return cleaned_list_values",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.198101Z",
     "iopub.execute_input": "2024-05-06T00:05:43.198929Z",
     "iopub.status.idle": "2024-05-06T00:05:43.208526Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.198904Z",
     "shell.execute_reply": "2024-05-06T00:05:43.207636Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.321239Z",
     "start_time": "2024-05-08T15:08:04.316813Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "def str_context_to_list(value):\n    list_values = value.strip('[]').split(' ')\n    cleaned_list_values = []\n    for item in list_values:\n        item.strip()\n        # if '\\n' in item:\n        #     item.replace('\\n', '')\n        if item != \"\":\n            cleaned_list_values.append(float(item))\n    return cleaned_list_values",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.209553Z",
     "iopub.execute_input": "2024-05-06T00:05:43.209807Z",
     "iopub.status.idle": "2024-05-06T00:05:43.218931Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.209785Z",
     "shell.execute_reply": "2024-05-06T00:05:43.218076Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.332209Z",
     "start_time": "2024-05-08T15:08:04.322240Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "# dataset = pd.read_csv(\"../datasets/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset.tags.nunique()/len(dataset)\n# labels = dataset1.tags.unique().tolist()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.220040Z",
     "iopub.execute_input": "2024-05-06T00:05:43.220299Z",
     "iopub.status.idle": "2024-05-06T00:05:43.230910Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.220277Z",
     "shell.execute_reply": "2024-05-06T00:05:43.230185Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.337164Z",
     "start_time": "2024-05-08T15:08:04.333209Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "max_length = 2048\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.231868Z",
     "iopub.execute_input": "2024-05-06T00:05:43.232130Z",
     "iopub.status.idle": "2024-05-06T00:05:43.240382Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.232108Z",
     "shell.execute_reply": "2024-05-06T00:05:43.239650Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.348879Z",
     "start_time": "2024-05-08T15:08:04.338165Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_6b():\n",
    "    embeding_object = torchtext.vocab.GloVe('6B', dim=50)\n",
    "    vec_6 = embeding_object.vectors.numpy()\n",
    "    vec_6 = np.append(vec_6, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_6 = np.append(vec_6, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_6 = embeding_object.stoi\n",
    "    vocab_6[\"<unk>\"] = len(vocab_6)\n",
    "    vocab_6[\"<pad>\"] = len(vocab_6)\n",
    "\n",
    "    embed_tensor_6 = torch.tensor(vec_6, dtype=torch.float)\n",
    "    embed_glove_6 = nn.Embedding.from_pretrained(embed_tensor_6, freeze=True)\n",
    "\n",
    "    embed_size_6 = len(vocab_6)\n",
    "\n",
    "    return embed_glove_6, vocab_6, embed_size_6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.243684Z",
     "iopub.execute_input": "2024-05-06T00:05:43.243960Z",
     "iopub.status.idle": "2024-05-06T00:05:43.251553Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.243937Z",
     "shell.execute_reply": "2024-05-06T00:05:43.250731Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.356886Z",
     "start_time": "2024-05-08T15:08:04.349873Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, dataset, vocab=None):\n",
    "        if vocab is None:\n",
    "            _, vocab, _ = get_glove_6b()\n",
    "        self.data = []\n",
    "\n",
    "        for sentence in dataset.text:\n",
    "            if len(sentence) > max_length:\n",
    "                continue\n",
    "            sentence_ids = []\n",
    "            for token in sentence:\n",
    "                try:\n",
    "                    sentence_ids.append(vocab[token])\n",
    "                except KeyError:\n",
    "                    sentence_ids.append(vocab[\"<unk>\"])\n",
    "            self.data.append(sentence_ids)\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        self.labels = dataset.tags\n",
    "\n",
    "        self.context = None\n",
    "\n",
    "        if 'context' in dataset.columns:\n",
    "            self.context = dataset.context\n",
    "        #     self.context = self.context[:1000]\n",
    "        #     \n",
    "        # self.data = self.data[:1000]\n",
    "        # self.labels = self.labels[:1000]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.context is None:\n",
    "            return self.data[idx], torch.tensor(self.labels.iloc[idx])\n",
    "        else:\n",
    "            return self.data[idx], torch.tensor(self.labels.iloc[idx]), self.context.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.252562Z",
     "iopub.execute_input": "2024-05-06T00:05:43.252814Z",
     "iopub.status.idle": "2024-05-06T00:05:43.262796Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.252793Z",
     "shell.execute_reply": "2024-05-06T00:05:43.261887Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.366795Z",
     "start_time": "2024-05-08T15:08:04.359878Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "vocab_collate_fn = None\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    global vocab_collate_fn\n",
    "    vocab = vocab_collate_fn\n",
    "    data_ids = []\n",
    "    labels = []\n",
    "    for dat in batch:\n",
    "        data_ids.append(dat[0])\n",
    "        labels.append(dat[1])\n",
    "\n",
    "    for i in range(len(data_ids)):\n",
    "        while len(data_ids[i]) < max_length:\n",
    "            data_ids[i].append(vocab[\"<pad>\"])\n",
    "\n",
    "    return data_ids, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.263849Z",
     "iopub.execute_input": "2024-05-06T00:05:43.264130Z",
     "iopub.status.idle": "2024-05-06T00:05:43.278455Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.264108Z",
     "shell.execute_reply": "2024-05-06T00:05:43.277633Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.373807Z",
     "start_time": "2024-05-08T15:08:04.367796Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "# vec = torchtext.vocab.GloVe('6B', dim=50).vectors.numpy()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.279480Z",
     "iopub.execute_input": "2024-05-06T00:05:43.279719Z",
     "iopub.status.idle": "2024-05-06T00:05:43.288870Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.279699Z",
     "shell.execute_reply": "2024-05-06T00:05:43.288147Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.378644Z",
     "start_time": "2024-05-08T15:08:04.374808Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_6b():\n",
    "    embeding_object = torchtext.vocab.GloVe('6B', dim=50)\n",
    "    vec_6 = embeding_object.vectors.numpy()\n",
    "    vec_6 = np.append(vec_6, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_6 = np.append(vec_6, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_6 = embeding_object.stoi\n",
    "    vocab_6[\"<unk>\"] = len(vocab_6)\n",
    "    vocab_6[\"<pad>\"] = len(vocab_6)\n",
    "\n",
    "    embed_tensor_6 = torch.tensor(vec_6, dtype=torch.float)\n",
    "    embed_glove_6 = nn.Embedding.from_pretrained(embed_tensor_6, freeze=True)\n",
    "\n",
    "    embed_size_6 = len(vocab_6)\n",
    "\n",
    "    return embed_glove_6, vocab_6, embed_size_6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.289984Z",
     "iopub.execute_input": "2024-05-06T00:05:43.290247Z",
     "iopub.status.idle": "2024-05-06T00:05:43.299790Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.290225Z",
     "shell.execute_reply": "2024-05-06T00:05:43.298902Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.386474Z",
     "start_time": "2024-05-08T15:08:04.380643Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_42b():\n",
    "    embeding_object = torchtext.vocab.GloVe('42B', dim=300)\n",
    "    vec_840 = embeding_object.vectors.numpy()\n",
    "    vec_840 = np.append(vec_840, np.zeros(300)).reshape(-1, 300)\n",
    "    vec_840 = np.append(vec_840, np.ones(300)).reshape(-1, 300)\n",
    "\n",
    "    vocab_840 = embeding_object.stoi\n",
    "    vocab_840[\"<unk>\"] = len(vocab_840)\n",
    "    vocab_840[\"<pad>\"] = len(vocab_840)\n",
    "\n",
    "    embed_tensor = torch.tensor(vec_840, dtype=torch.float)\n",
    "    embed_glove_840 = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "\n",
    "    embed_size_840 = len(vec_840)\n",
    "\n",
    "    return embed_glove_840, vocab_840, embed_size_840"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.300942Z",
     "iopub.execute_input": "2024-05-06T00:05:43.301719Z",
     "iopub.status.idle": "2024-05-06T00:05:43.313229Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.301689Z",
     "shell.execute_reply": "2024-05-06T00:05:43.312392Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.393747Z",
     "start_time": "2024-05-08T15:08:04.387475Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_twitter():\n",
    "    embeding_object = torchtext.vocab.GloVe('twitter.27B', dim=50)\n",
    "    vec_twitter = embeding_object.vectors.numpy()\n",
    "    vec_twitter = np.append(vec_twitter, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_twitter = np.append(vec_twitter, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_twitter = embeding_object.stoi\n",
    "    vocab_twitter[\"<unk>\"] = len(vocab_twitter)\n",
    "    vocab_twitter[\"<pad>\"] = len(vocab_twitter)\n",
    "\n",
    "    embed_tensor = torch.tensor(vec_twitter, dtype=torch.float)\n",
    "    embed_glove_twitter = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "\n",
    "    embed_size_twitter = len(vec_twitter)\n",
    "\n",
    "    return embed_glove_twitter, vocab_twitter, embed_size_twitter"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.314366Z",
     "iopub.execute_input": "2024-05-06T00:05:43.314624Z",
     "iopub.status.idle": "2024-05-06T00:05:43.323785Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.314603Z",
     "shell.execute_reply": "2024-05-06T00:05:43.323024Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.400862Z",
     "start_time": "2024-05-08T15:08:04.394749Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": "## WSD 1",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# # dataset = pd.read_csv(\"../datasets/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset_wsd_1 = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# labels = dataset_wsd_1.tags.unique().tolist()\n# dataset_wsd_1.tags = dataset_wsd_1.tags.apply(labels.index)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.324970Z",
     "iopub.execute_input": "2024-05-06T00:05:43.325264Z",
     "iopub.status.idle": "2024-05-06T00:05:43.334553Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.325241Z",
     "shell.execute_reply": "2024-05-06T00:05:43.333792Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.406421Z",
     "start_time": "2024-05-08T15:08:04.401863Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "# dataset_wsd_1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.335509Z",
     "iopub.execute_input": "2024-05-06T00:05:43.335763Z",
     "iopub.status.idle": "2024-05-06T00:05:43.348685Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.335741Z",
     "shell.execute_reply": "2024-05-06T00:05:43.348005Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.411567Z",
     "start_time": "2024-05-08T15:08:04.407423Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "# train, test = train_test_split(dataset_wsd_1, test_size=0.2, shuffle=True,stratify=dataset_wsd_1.tags)\n\n# train_dataset1 = myDataset(train)\n# test_dataset1 = myDataset(test)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.349760Z",
     "iopub.execute_input": "2024-05-06T00:05:43.350040Z",
     "iopub.status.idle": "2024-05-06T00:05:43.357851Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.350017Z",
     "shell.execute_reply": "2024-05-06T00:05:43.357090Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.416505Z",
     "start_time": "2024-05-08T15:08:04.412568Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def wsd1_creator(embeding):\n",
    "    dataset_wsd_1 = pd.read_csv(f\"{working_dir}/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_wsd_1.tags.unique().tolist()\n",
    "    dataset_wsd_1.tags = dataset_wsd_1.tags.apply(labels.index)\n",
    "\n",
    "    train, test = train_test_split(dataset_wsd_1, test_size=0.2, shuffle=True, stratify=dataset_wsd_1.tags)\n",
    "\n",
    "    train, test = myDataset(train, embeding), myDataset(test, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.358675Z",
     "iopub.execute_input": "2024-05-06T00:05:43.358899Z",
     "iopub.status.idle": "2024-05-06T00:05:43.368508Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.358879Z",
     "shell.execute_reply": "2024-05-06T00:05:43.367801Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.424013Z",
     "start_time": "2024-05-08T15:08:04.417506Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader1 = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n# test_dataloader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.369468Z",
     "iopub.execute_input": "2024-05-06T00:05:43.369721Z",
     "iopub.status.idle": "2024-05-06T00:05:43.378294Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.369700Z",
     "shell.execute_reply": "2024-05-06T00:05:43.377468Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.429174Z",
     "start_time": "2024-05-08T15:08:04.425012Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": "# for batch in tqdm(train_dataloader):\n#     embedded_tokens = batch[0]\n#     labels = batch[1]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.379397Z",
     "iopub.execute_input": "2024-05-06T00:05:43.379683Z",
     "iopub.status.idle": "2024-05-06T00:05:43.387747Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.379652Z",
     "shell.execute_reply": "2024-05-06T00:05:43.386927Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.434311Z",
     "start_time": "2024-05-08T15:08:04.430175Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": "## WSD 2",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_wsd_2 = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_wsd_2.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset_wsd_2 = dataset_wsd_2.dropna()\n\n# labels = dataset_wsd_2.tags.unique().tolist()\n# dataset_wsd_2.tags = dataset_wsd_2.tags.apply(labels.index)\n\n# dataset_wsd_2.context = dataset_wsd_2.context.apply(str_context_to_list)\n\n# dataset_wsd_2.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.388766Z",
     "iopub.execute_input": "2024-05-06T00:05:43.389025Z",
     "iopub.status.idle": "2024-05-06T00:05:43.397392Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.389000Z",
     "shell.execute_reply": "2024-05-06T00:05:43.396704Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.440118Z",
     "start_time": "2024-05-08T15:08:04.435311Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "# train_wsd_2, test_wsd_2 = train_test_split(dataset_wsd_2, stratify=dataset_wsd_2['tags'], test_size=0.2, random_state=42)\n# train_dataset_wsd_2, test_dataset_wsd_2 = myDataset(train_wsd_2), myDataset(test_wsd_2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.398492Z",
     "iopub.execute_input": "2024-05-06T00:05:43.398776Z",
     "iopub.status.idle": "2024-05-06T00:05:43.406594Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.398748Z",
     "shell.execute_reply": "2024-05-06T00:05:43.405762Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.444626Z",
     "start_time": "2024-05-08T15:08:04.441118Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "def wsd2_creator(embeding):\n",
    "    dataset_wsd_2 = pd.read_csv(f\"{working_dir}/tonetags_wsd_2.csv\", index_col=0, converters={\"text\": str_to_list})\n",
    "    dataset_wsd_2 = dataset_wsd_2.dropna()\n",
    "\n",
    "    labels = dataset_wsd_2.tags.unique().tolist()\n",
    "    dataset_wsd_2.tags = dataset_wsd_2.tags.apply(labels.index)\n",
    "    dataset_wsd_2.context = dataset_wsd_2.context.apply(str_context_to_list)\n",
    "\n",
    "    train_wsd_2, test_wsd_2 = train_test_split(dataset_wsd_2, stratify=dataset_wsd_2['tags'], test_size=0.2,\n",
    "                                               random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_wsd_2, embeding), myDataset(test_wsd_2, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.407694Z",
     "iopub.execute_input": "2024-05-06T00:05:43.407962Z",
     "iopub.status.idle": "2024-05-06T00:05:43.420210Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.407933Z",
     "shell.execute_reply": "2024-05-06T00:05:43.419384Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.452980Z",
     "start_time": "2024-05-08T15:08:04.445630Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_wsd_2 = DataLoader(train_dataset_wsd_2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_wsd_2 = DataLoader(test_dataset_wsd_2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.421336Z",
     "iopub.execute_input": "2024-05-06T00:05:43.421572Z",
     "iopub.status.idle": "2024-05-06T00:05:43.430955Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.421552Z",
     "shell.execute_reply": "2024-05-06T00:05:43.430083Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.459802Z",
     "start_time": "2024-05-08T15:08:04.456966Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "## Clean_corrected dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_clean_corrected = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_dataset_tumblr_clean_corrected_text.csv\", converters={\"text\": str_to_list})\n\n# labels = dataset_clean_corrected.tags.unique().tolist()\n# dataset_clean_corrected.tags =dataset_clean_corrected.tags.apply(labels.index)\n\n# dataset_clean_corrected.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.432111Z",
     "iopub.execute_input": "2024-05-06T00:05:43.432383Z",
     "iopub.status.idle": "2024-05-06T00:05:43.441669Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.432361Z",
     "shell.execute_reply": "2024-05-06T00:05:43.440797Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.466948Z",
     "start_time": "2024-05-08T15:08:04.460793Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "# train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected, stratify=dataset_clean_corrected['tags'], test_size=0.2, random_state=42)\n# train_dataset_clean_corrected, test_dataset_clean_corrected = myDataset(train_clean_corrected), myDataset(test_clean_corrected)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.447641Z",
     "iopub.execute_input": "2024-05-06T00:05:43.448013Z",
     "iopub.status.idle": "2024-05-06T00:05:43.451951Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.447983Z",
     "shell.execute_reply": "2024-05-06T00:05:43.451140Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.472634Z",
     "start_time": "2024-05-08T15:08:04.467948Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_corrected_creator(embeding):\n",
    "    dataset_clean_corrected = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean_corrected_text.csv\",\n",
    "                                          converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean_corrected.tags.unique().tolist()\n",
    "    dataset_clean_corrected.tags = dataset_clean_corrected.tags.apply(labels.index)\n",
    "\n",
    "    train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected,\n",
    "                                                                   stratify=dataset_clean_corrected['tags'],\n",
    "                                                                   test_size=0.2, random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean_corrected, embeding), myDataset(test_clean_corrected, embeding)\n",
    "    train_dataloader_clean_corrected = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                  drop_last=True)\n",
    "    test_dataloader_clean_corrected = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                 drop_last=True)\n",
    "    return train_dataloader_clean_corrected, test_dataloader_clean_corrected"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.452959Z",
     "iopub.execute_input": "2024-05-06T00:05:43.453297Z",
     "iopub.status.idle": "2024-05-06T00:05:43.463461Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.453267Z",
     "shell.execute_reply": "2024-05-06T00:05:43.462619Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.479990Z",
     "start_time": "2024-05-08T15:08:04.473634Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_clean_corrected = DataLoader(train_dataset_clean_corrected, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_clean_corrected = DataLoader(test_dataset_clean_corrected, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.464546Z",
     "iopub.execute_input": "2024-05-06T00:05:43.464873Z",
     "iopub.status.idle": "2024-05-06T00:05:43.477726Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.464832Z",
     "shell.execute_reply": "2024-05-06T00:05:43.476772Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.485227Z",
     "start_time": "2024-05-08T15:08:04.480991Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": "## Clean",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_clean = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_dataset_tumblr_clean.csv\", converters={\"text\": str_to_list})\n\n# labels = dataset_clean.tags.unique().tolist()\n# dataset_clean.tags =dataset_clean.tags.apply(labels.index)\n\n# dataset_clean.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.478864Z",
     "iopub.execute_input": "2024-05-06T00:05:43.479179Z",
     "iopub.status.idle": "2024-05-06T00:05:43.487999Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.479156Z",
     "shell.execute_reply": "2024-05-06T00:05:43.487249Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.489860Z",
     "start_time": "2024-05-08T15:08:04.486226Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "# train_clean, test_clean = train_test_split(dataset_clean, stratify=dataset_clean['tags'], test_size=0.2, random_state=42)\n# train_dataset_clean, test_dataset_clean = myDataset(train_clean), myDataset(test_clean)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.488996Z",
     "iopub.execute_input": "2024-05-06T00:05:43.489252Z",
     "iopub.status.idle": "2024-05-06T00:05:43.499237Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.489231Z",
     "shell.execute_reply": "2024-05-06T00:05:43.498490Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.495324Z",
     "start_time": "2024-05-08T15:08:04.490859Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_creator(embeding):\n",
    "    dataset_clean = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean.csv\", converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean.tags.unique().tolist()\n",
    "    dataset_clean.tags = dataset_clean.tags.apply(labels.index)\n",
    "\n",
    "    train_clean, test_clean = train_test_split(dataset_clean, stratify=dataset_clean['tags'], test_size=0.2,\n",
    "                                               random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean, embeding), myDataset(test_clean, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.500329Z",
     "iopub.execute_input": "2024-05-06T00:05:43.501203Z",
     "iopub.status.idle": "2024-05-06T00:05:43.509162Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.501171Z",
     "shell.execute_reply": "2024-05-06T00:05:43.508436Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.502558Z",
     "start_time": "2024-05-08T15:08:04.497324Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_clean = DataLoader(train_dataset_clean, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_clean = DataLoader(test_dataset_clean, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.510249Z",
     "iopub.execute_input": "2024-05-06T00:05:43.511074Z",
     "iopub.status.idle": "2024-05-06T00:05:43.522443Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.511050Z",
     "shell.execute_reply": "2024-05-06T00:05:43.521527Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.509471Z",
     "start_time": "2024-05-08T15:08:04.503559Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_corrected_wsd2_creator(embeding):\n",
    "    dataset_clean_corrected = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean_corrected_text_wsd_2.csv\",\n",
    "                                          converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean_corrected.tags.unique().tolist()\n",
    "    dataset_clean_corrected.tags = dataset_clean_corrected.tags.apply(labels.index)\n",
    "\n",
    "    train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected,\n",
    "                                                                   stratify=dataset_clean_corrected['tags'],\n",
    "                                                                   test_size=0.2, random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean_corrected, embeding), myDataset(test_clean_corrected, embeding)\n",
    "    train_dataloader_clean_corrected = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                  drop_last=True)\n",
    "    test_dataloader_clean_corrected = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                 drop_last=True)\n",
    "    return train_dataloader_clean_corrected, test_dataloader_clean_corrected\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.517663Z",
     "start_time": "2024-05-08T15:08:04.510471Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": "## Train utils",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_result = {}\n",
    "\n",
    "\n",
    "def update_result(d):\n",
    "    global epoch_result\n",
    "\n",
    "    for k in d.keys():\n",
    "        if k in list(epoch_result.keys()):\n",
    "            raise Exception\n",
    "\n",
    "    epoch_result.update(d)\n",
    "\n",
    "\n",
    "def log():\n",
    "    global epoch_result\n",
    "    wandb.log(epoch_result)\n",
    "    epoch_result.clear()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.523534Z",
     "iopub.execute_input": "2024-05-06T00:05:43.523814Z",
     "iopub.status.idle": "2024-05-06T00:05:43.533182Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.523784Z",
     "shell.execute_reply": "2024-05-06T00:05:43.532308Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:04.523408Z",
     "start_time": "2024-05-08T15:08:04.518662Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "import torchmetrics\n",
    "def train_epoch(trainloader, model, opt, loss_criterion):\n",
    "    global epoch_result\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    #loss для одной epoch\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    #применить для каждого бача из trainload\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    number_of_batches = len(list(trainloader))\n",
    "    result = []\n",
    "    result1 = []\n",
    "    for batch_idx, inputs_all in enumerate(trainloader):\n",
    "\n",
    "        inputs, targets, context = None, None, None\n",
    "        if len(inputs_all) == 2:\n",
    "            inputs, targets = inputs_all\n",
    "            inputs = torch.tensor(inputs)\n",
    "            targets = torch.tensor(targets)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        else:\n",
    "            inputs, targets, context = inputs_all\n",
    "            inputs = torch.tensor(inputs)\n",
    "            targets = torch.tensor(targets)\n",
    "            context = torch.tensor(context)\n",
    "            inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "        #тренировка\n",
    "        opt.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "\n",
    "        #шаг оптимизации/loss funct       \n",
    "        loss = loss_criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        predicted = outputs.argmax(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        #подсчет точности\n",
    "        total += targets.size(0)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        result.append(targets)\n",
    "        result1.append(outputs)\n",
    "\n",
    "    del context\n",
    "    del inputs\n",
    "    del targets\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # запись loss/acc для train в классе statistic, и в Tensorboard\n",
    "\n",
    "    #         print(\"epoch---------------\")\n",
    "    num_classes=19\n",
    "    accuracy_func = torchmetrics.classification.Accuracy(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                         top_k=3)\n",
    "    print(\"train\")\n",
    "    print(\"epoch: time\", datetime.datetime.now() - start_time)\n",
    "    print(\"loss: \", train_loss / total)\n",
    "\n",
    "    # update_result({\"loss/train\": train_loss / total, \"acc/train\": correct / total})\n",
    "    y_train,y_pred = torch.cat(result).reshape(-1).cpu(), torch.cat(result1).cpu()\n",
    "    update_result({\"loss/train\": train_loss / total, \"acc/train\": accuracy_func(y_pred,y_train)})\n",
    "    \n",
    "\n",
    "\n",
    "def test(testloader, model, loss_criterion):\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs_all in enumerate(testloader):\n",
    "\n",
    "            inputs, targets, context = None, None, None\n",
    "            if len(inputs_all) == 2:\n",
    "                inputs, targets = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            else:\n",
    "                inputs, targets, context = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                context = torch.tensor(context)\n",
    "                inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "\n",
    "            outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "            #             inputs, targets = inputs.to(device), targets.to(device)\n",
    "            #             logits = model(inputs)\n",
    "            #             outputs = torch.nn.functional.log_softmax(logits,dim=1)\n",
    "\n",
    "            loss = loss_criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            #             _, predicted = outputs.exp(dim=1).max(1)\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        del context\n",
    "        del inputs\n",
    "        del targets\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # запись loss/acc для test в классе statistic, и в Tensorboard\n",
    "    print('test')\n",
    "    print(\"loss: \", test_loss / total, \"acc: \", correct / total)\n",
    "    update_result({\"loss/test\": test_loss / total, \"acc/test\": correct / total})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.534631Z",
     "iopub.execute_input": "2024-05-06T00:05:43.534898Z",
     "iopub.status.idle": "2024-05-06T00:05:43.553840Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.534876Z",
     "shell.execute_reply": "2024-05-06T00:05:43.552892Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.615277Z",
     "start_time": "2024-05-08T15:08:04.524410Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "def inference(testloader, model):\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "    result1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs_all in enumerate(testloader):\n",
    "            inputs, targets, context = None, None, None\n",
    "            if len(inputs_all) == 2:\n",
    "                inputs, targets = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            else:\n",
    "                inputs, targets, context = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                context = torch.tensor(context)\n",
    "                inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "\n",
    "            outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "\n",
    "            predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "            result.append(predicted)\n",
    "            result1.append(outputs)\n",
    "        del context\n",
    "        del inputs\n",
    "        del targets\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return torch.cat(result).reshape(-1).cpu(), torch.cat(result1).cpu()\n",
    "\n",
    "\n",
    "def get_targets(testloader):\n",
    "    result = []\n",
    "    for batch_idx, inputs_all in enumerate(testloader):\n",
    "        inputs, targets, context = None, None, None\n",
    "        if len(inputs_all) == 2:\n",
    "            inputs, targets = inputs_all\n",
    "            targets = torch.tensor(targets)\n",
    "        else:\n",
    "            inputs, targets, context = inputs_all\n",
    "            targets = torch.tensor(targets)\n",
    "        result.append(targets)\n",
    "    del context\n",
    "    del inputs\n",
    "    del targets\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(result).reshape(-1).cpu()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:21:43.104716Z",
     "iopub.execute_input": "2024-05-06T00:21:43.105503Z",
     "iopub.status.idle": "2024-05-06T00:21:43.116733Z",
     "shell.execute_reply.started": "2024-05-06T00:21:43.105473Z",
     "shell.execute_reply": "2024-05-06T00:21:43.115811Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.624413Z",
     "start_time": "2024-05-08T15:08:05.616279Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def train(epoch, trainloader, testloader, model, loss, opt):\n",
    "    global current_epoch_number\n",
    "    global total_epoch\n",
    "    total_epoch = epoch\n",
    "    for current_epoch_number in range(epoch):\n",
    "        print(\"epoch\", current_epoch_number)\n",
    "        train_epoch(trainloader=trainloader, model=model, opt=opt, loss_criterion=loss)\n",
    "        test(testloader=testloader, model=model, loss_criterion=loss)\n",
    "\n",
    "        outputs, y_scores = inference(model=model, testloader=testloader)\n",
    "        targets = get_targets(testloader=testloader)\n",
    "        evaluate(targets, outputs, y_scores)\n",
    "\n",
    "        log()\n",
    "    outputs,y_scores = inference(model=model, testloader=testloader)\n",
    "    targets = get_targets(testloader=testloader)\n",
    "    evaluate_final_stage(outputs, targets, y_scores)\n",
    "\n",
    "#         if scheduler is None:\n",
    "#             continue\n",
    "#         scheduler.step()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.628898Z",
     "iopub.status.idle": "2024-05-06T00:05:43.629254Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.629093Z",
     "shell.execute_reply": "2024-05-06T00:05:43.629107Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.632436Z",
     "start_time": "2024-05-08T15:08:05.625414Z"
    }
   },
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "# def evaluate(y_true,y_pred):\n",
    "#     from sklearn.metrics import f1_score\n",
    "#     from sklearn.metrics import precision_score\n",
    "#     from sklearn.metrics import recall_score\n",
    "\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#     if (y_true<0).all():\n",
    "#         return\n",
    "#     # Переписать\n",
    "#     # Добавить confusion matrix\n",
    "\n",
    "\n",
    "# #     result = {\"acc\": accuracy_score(y_pred_class,y_true),\n",
    "# #               }\n",
    "\n",
    "\n",
    "#     wandb.log(result,step=current_epoch_number)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.630487Z",
     "iopub.status.idle": "2024-05-06T00:05:43.630817Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.630657Z",
     "shell.execute_reply": "2024-05-06T00:05:43.630671Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.637331Z",
     "start_time": "2024-05-08T15:08:05.633437Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# \n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import top_k_accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred, y_scores=None):\n",
    "    num_classes = 19\n",
    "    accuracy_func = torchmetrics.classification.Accuracy(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                         top_k=3)\n",
    "    precision_func = torchmetrics.classification.Precision(task='multiclass', num_classes=num_classes,\n",
    "                                                           average='weighted', top_k=3)\n",
    "    recall_func = torchmetrics.classification.Recall(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                     top_k=3)\n",
    "    f1score_func = torchmetrics.classification.F1Score(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                       top_k=3)\n",
    "\n",
    "    # if (y_true<0).all():\n",
    "    #     return\n",
    "    # \n",
    "    # f1_one_vs_all = f1_score(y_pred,y_true,average=None)\n",
    "    # recall_one_vs_all = recall_score(y_pred,y_true,average=None)\n",
    "    # recall_one_vs_all = recall_score(y_pred,y_true,average=None)\n",
    "\n",
    "    result = {\"acc_w\": accuracy_func(y_scores, y_true),\n",
    "              \"precision\": precision_func(y_scores, y_true),\n",
    "              \"recall\": recall_func(y_scores, y_true),\n",
    "              \"f1\": f1score_func(y_scores, y_true)}\n",
    "\n",
    "    # result = {\"acc\": accuracy_score(y_true,y_pred),\n",
    "    #           \"f1_micro\":f1_score(y_true,y_pred,average='micro'),\n",
    "    #           \"precision_micro\": precision_score(y_true,y_pred,average='micro'),\n",
    "    #           \"recall_micro\":recall_score(y_true,y_pred,average='micro'),\n",
    "    #           \"top_k_acc\":top_k_accuracy_score(y_true,y_pred,k=3)\n",
    "    #           }\n",
    "    # result.update({f\"precision_one_vs_all_{i}\":val for i,val in enumerate(f1_one_vs_all)})\n",
    "    # result.update({f\"recall_one_vs_all_{i}\":val for i,val in enumerate(f1_one_vs_all)})\n",
    "\n",
    "    #     if y_scores is None:\n",
    "    #         update_result(result)\n",
    "    #         return \n",
    "\n",
    "    #     result.update({\"acc_top_k\":top_k_accuracy_score(y_true,y_scores,labels=range(20))})\n",
    "\n",
    "    update_result(result)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def evaluate_final_stage(y_true, y_pred, y_scores):\n",
    "    # print(result)\n",
    "    labels = range(20)\n",
    "    try:\n",
    "        table1 = wandb.Table(columns=[\"tag\", \"true_tag\", \"y_scores\"], data=y_pred)\n",
    "        table2 = wandb.Table(columns=[\"tag\", \"true_tag\", \"y_scores\"], data= y_true)\n",
    "        table3 = wandb.Table(columns=[\"tag\", \"true_tag\", \"y_scores\"], data=y_scores)\n",
    "        pd.DataFrame(y_pred.numpy()).to_csv(time.time()+\"pred\")\n",
    "        pd.DataFrame(y_true.numpy()).to_csv(time.time()+\"true\")\n",
    "        pd.DataFrame(y_scores.numpy()).to_csv(time.time()+\"score\")\n",
    "\n",
    "        cm = wandb.plot.confusion_matrix(\n",
    "            y_true=y_true,\n",
    "            preds=y_pred,\n",
    "            class_names=labels)\n",
    "\n",
    "        wandb.log({\"predictions\": table1})\n",
    "        wandb.log({\"predictions\": table2})\n",
    "        wandb.log({\"predictions\": table3})\n",
    "        wandb.log({\"conf_mat\": cm})\n",
    "    except:\n",
    "        print(\"error accured\")\n",
    "        \n",
    "\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.632115Z",
     "iopub.status.idle": "2024-05-06T00:05:43.632430Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.632278Z",
     "shell.execute_reply": "2024-05-06T00:05:43.632291Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.648254Z",
     "start_time": "2024-05-08T15:08:05.638332Z"
    }
   },
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": "## Model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T19:35:29.839646Z",
     "start_time": "2024-04-14T19:35:29.83776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "# input_dim, hidden_dim, layer_dim, output_dim",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.634010Z",
     "iopub.status.idle": "2024-05-06T00:05:43.634321Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.634169Z",
     "shell.execute_reply": "2024-05-06T00:05:43.634182Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.655983Z",
     "start_time": "2024-05-08T15:08:05.649254Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTagsRNN(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100, rnn=True):\n",
    "        super(ToneTagsRNN, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                                bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "        if not (context is None):\n",
    "            embedded = torch.cat(embedded, context)\n",
    "            embedded = self.fc0(embedded)\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:11:41.340827Z",
     "iopub.execute_input": "2024-05-06T00:11:41.341483Z",
     "iopub.status.idle": "2024-05-06T00:11:41.356987Z",
     "shell.execute_reply.started": "2024-05-06T00:11:41.341452Z",
     "shell.execute_reply": "2024-05-06T00:11:41.356024Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.665554Z",
     "start_time": "2024-05-08T15:08:05.656976Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTagsLSTM(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100, rnn=False):\n",
    "        super(ToneTagsLSTM, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                                 bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "        if not (context is None):\n",
    "            embedded = torch.cat(embedded, context)\n",
    "            embedded = self.fc0(embedded)\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.638056Z",
     "iopub.status.idle": "2024-05-06T00:05:43.638503Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.638268Z",
     "shell.execute_reply": "2024-05-06T00:05:43.638286Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.674358Z",
     "start_time": "2024-05-08T15:08:05.666550Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTags_After_Model_RNN(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100):\n",
    "        super(ToneTags_After_Model_RNN, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.seq_layer = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim,\n",
    "                                      num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, 1024)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        output, hidden = self.seq_layer(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        # if not (context is None):\n",
    "        rnn_out = torch.cat(rnn_out, context)\n",
    "        rnn_out = self.fc4(rnn_out)\n",
    "\n",
    "        # fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(rnn_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.639727Z",
     "iopub.status.idle": "2024-05-06T00:05:43.640174Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.639933Z",
     "shell.execute_reply": "2024-05-06T00:05:43.639950Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.683091Z",
     "start_time": "2024-05-08T15:08:05.675358Z"
    }
   },
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTags_After_Model_LSTM(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100):\n",
    "        super(ToneTags_After_Model_LSTM, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.seq_layer = torch.nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim,\n",
    "                                       num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, 1024)\n",
    "        # self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, hidden_dim * max_length * 2)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        output, hidden = self.seq_layer(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        # if not (context is None):\n",
    "        rnn_out = torch.cat(rnn_out, context)\n",
    "        rnn_out = self.fc4(rnn_out)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.641468Z",
     "iopub.status.idle": "2024-05-06T00:05:43.641912Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.641681Z",
     "shell.execute_reply": "2024-05-06T00:05:43.641698Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.692473Z",
     "start_time": "2024-05-08T15:08:05.684094Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "# class ToneTagsRNN(torch.nn.Module):\n",
    "#     def __init__(self,embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.4,embed_context_size=100):\n",
    "#         super(ToneTagsRNN, self).__init__()\n",
    "#         # vocab_size = 400002\n",
    "#         # embedding_dim = 50\n",
    "#         # hidden_dim_lstm = 30\n",
    "\n",
    "#         # output_size = 19\n",
    "#         self.rnn_output_size = hidden_dim*max_length*2\n",
    "\n",
    "#         self.embedding = embedding\n",
    "#         self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "#         self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "# #         (64x6400 and 409600x1024)\n",
    "# #         50*4096*2\n",
    "#         self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "#         self.fc1 = nn.Linear(hidden_dim*max_length*2, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, output_size)\n",
    "#         # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "#     def forward(self,x,context=None):\n",
    "#         activation = torch.nn.ReLU()\n",
    "#         embedded = self.embedding(x)\n",
    "#         if not(context is None):\n",
    "#             embedded = torch.cat(embedded,context)\n",
    "#             embedded = self.fc0(embedded)\n",
    "\n",
    "#         output, hidden = self.rnn(embedded)\n",
    "\n",
    "#         rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "\n",
    "#         fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "#         fc2_out = activation(self.fc2(fc1_out))\n",
    "#         out = self.fc3(fc2_out)\n",
    "# #         \n",
    "#         return torch.nn.Softmax()(out)\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# # vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.643443Z",
     "iopub.status.idle": "2024-05-06T00:05:43.643744Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.643596Z",
     "shell.execute_reply": "2024-05-06T00:05:43.643608Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.698966Z",
     "start_time": "2024-05-08T15:08:05.693472Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": "## Experiments",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-5,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset_clean\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader_clean,testloader=test_dataloader_clean,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.645061Z",
     "iopub.status.idle": "2024-05-06T00:05:43.645390Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.645226Z",
     "shell.execute_reply": "2024-05-06T00:05:43.645239Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.703963Z",
     "start_time": "2024-05-08T15:08:05.699968Z"
    }
   },
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-3,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset2\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader,testloader=test_dataloader,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.646617Z",
     "iopub.status.idle": "2024-05-06T00:05:43.647070Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.646824Z",
     "shell.execute_reply": "2024-05-06T00:05:43.646842Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.709299Z",
     "start_time": "2024-05-08T15:08:05.704963Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-3,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset2\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader,testloader=test_dataloader,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.648456Z",
     "iopub.status.idle": "2024-05-06T00:05:43.648756Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.648608Z",
     "shell.execute_reply": "2024-05-06T00:05:43.648620Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.715908Z",
     "start_time": "2024-05-08T15:08:05.710299Z"
    }
   },
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": "## Tuning",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "datasets_list = {\"clean_corrected_wsd_2\": clean_corrected_wsd2_creator,\n",
    "                 \"wsd2\": wsd2_creator,\n",
    "                 }\n",
    "embedings_list = {\n",
    "    # \"6B\":get_glove_6b,\n",
    "    # \"840B\":get_glove_42b,\n",
    "    \"twitter\": get_glove_twitter\n",
    "}\n",
    "models_list = {\n",
    "    \"RNN\": ToneTagsRNN,\n",
    "    \"After_Model_RNN\": ToneTags_After_Model_RNN,\n",
    "    # \"LSTM\":ToneTagsLSTM,\n",
    "    \"After_Model_LSTM\": ToneTags_After_Model_LSTM\n",
    "}\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.649855Z",
     "iopub.status.idle": "2024-05-06T00:05:43.650187Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.650026Z",
     "shell.execute_reply": "2024-05-06T00:05:43.650040Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:08:05.722093Z",
     "start_time": "2024-05-08T15:08:05.716909Z"
    }
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": [
    "configs1 = {\n",
    "    \"epoch\": {'value': 10},\n",
    "    \"optimizer\": {'value': 'adam'},\n",
    "\n",
    "    \"betas\": {'value': (0.9, 0.99)},\n",
    "\n",
    "    \"optLr\": {'values': [1e-5, 1e-4]},\n",
    "\n",
    "    \"dataset\": {'values': list(datasets_list.keys())},\n",
    "    \"model\": {'values': list(models_list.keys())},\n",
    "    \"embeding\": {'values': list(embedings_list.keys())},\n",
    "    \"loss\": {'value': \"CrossEntropy\"}\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n",
    "# \n",
    "\n",
    "\n",
    "def run_experiment(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        try:\n",
    "            global vocab_collate_fn\n",
    "            config = wandb.config\n",
    "    \n",
    "            embeding, vocab, e_size = embedings_list[config['embeding']]()\n",
    "            vocab_collate_fn = vocab\n",
    "    \n",
    "            model = models_list[config['model']]\n",
    "            model = model(embeding, vocab_size=e_size)\n",
    "    \n",
    "            opt = torch.optim.Adam(params=model.parameters(), lr=config['optLr'])\n",
    "    \n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "            train_loader, test_loader = datasets_list[config['dataset']](vocab)\n",
    "    \n",
    "            train(epoch=config['epoch'], trainloader=train_loader, testloader=test_loader, model=model, loss=loss, opt=opt)\n",
    "    \n",
    "            del train_loader\n",
    "            del test_loader\n",
    "            del embeding\n",
    "            del vocab\n",
    "    \n",
    "            vocab_collate_fn = None\n",
    "    \n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "}\n",
    "sweep_config['metric'] = {'name': 'loss/train',\n",
    "                          'goal': 'minimize'\n",
    "                          }\n",
    "sweep_config['parameters'] = configs1\n",
    "sweep_id1 = wandb.sweep(sweep_config, project=\"AML\")\n",
    "# sweep_config['parameters'] = configs2\n",
    "# sweep_id2 = wandb.sweep(sweep_config, project=\"kontur\")\n",
    "\n",
    "wandb.agent(sweep_id1, run_experiment)\n",
    "# wandb.agent(sweep_id2, run_experiment)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.651261Z",
     "iopub.status.idle": "2024-05-06T00:05:43.651558Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.651408Z",
     "shell.execute_reply": "2024-05-06T00:05:43.651420Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T17:23:49.466604Z",
     "start_time": "2024-05-08T15:08:05.723094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wogrht6r\n",
      "Sweep URL: https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 3w5lkobh with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: RNN\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_200824-3w5lkobh</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/3w5lkobh' target=\"_blank\">proud-sweep-1</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/3w5lkobh' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/3w5lkobh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train\n",
      "epoch: time 0:02:54.969089\n",
      "loss:  0.08323159860205774\n",
      "test\n",
      "loss:  0.08305125929555802 acc:  0.16892688679245282\n",
      "epoch 1\n",
      "train\n",
      "epoch: time 0:02:46.756752\n",
      "loss:  0.08305116687399904\n",
      "test\n",
      "loss:  0.08299419688728621 acc:  0.16898584905660377\n",
      "epoch 2\n",
      "train\n",
      "epoch: time 0:02:47.953356\n",
      "loss:  0.08298604416007767\n",
      "test\n",
      "loss:  0.08297510012140814 acc:  0.16774764150943397\n",
      "epoch 3\n",
      "train\n",
      "epoch: time 0:02:48.412479\n",
      "loss:  0.08292873188663753\n",
      "test\n",
      "loss:  0.08298668462150502 acc:  0.16810141509433962\n",
      "epoch 4\n",
      "train\n",
      "epoch: time 0:02:49.877820\n",
      "loss:  0.08283913292401364\n",
      "test\n",
      "loss:  0.0829818123354102 acc:  0.16721698113207548\n",
      "epoch 5\n",
      "train\n",
      "epoch: time 0:02:50.307178\n",
      "loss:  0.08263179245025438\n",
      "test\n",
      "loss:  0.08304829012672856 acc:  0.16780660377358492\n",
      "epoch 6\n",
      "train\n",
      "epoch: time 0:02:50.670029\n",
      "loss:  0.08232693103577694\n",
      "test\n",
      "loss:  0.08308612028101706 acc:  0.16751179245283018\n",
      "epoch 7\n",
      "train\n",
      "epoch: time 0:02:51.649722\n",
      "loss:  0.08191910725450156\n",
      "test\n",
      "loss:  0.0831830841612141 acc:  0.16668632075471698\n",
      "epoch 8\n",
      "train\n",
      "epoch: time 0:02:51.289346\n",
      "loss:  0.08142342607592054\n",
      "test\n",
      "loss:  0.08326179655093068 acc:  0.16768867924528302\n",
      "epoch 9\n",
      "train\n",
      "epoch: time 0:02:50.993571\n",
      "loss:  0.08092604374343698\n",
      "test\n",
      "loss:  0.08358312402412577 acc:  0.16497641509433963\n",
      "error accured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e39291e28334b3097de61b1e8d3b69d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>██▆▆▅▆▅▄▆▁</td></tr><tr><td>acc/train</td><td>▁▂▂▂▂▃▄▅▇█</td></tr><tr><td>acc_w</td><td>██████▁▇▆▆</td></tr><tr><td>f1</td><td>▁▁▂▁▂▂▇▄▄█</td></tr><tr><td>loss/test</td><td>▂▁▁▁▁▂▂▃▄█</td></tr><tr><td>loss/train</td><td>█▇▇▇▇▆▅▄▃▁</td></tr><tr><td>precision</td><td>▃▄▂▁▂█▂▄▅▅</td></tr><tr><td>recall</td><td>██████▁▇▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>0.16498</td></tr><tr><td>acc/train</td><td>0.43289</td></tr><tr><td>acc_w</td><td>0.40973</td></tr><tr><td>f1</td><td>0.11904</td></tr><tr><td>loss/test</td><td>0.08358</td></tr><tr><td>loss/train</td><td>0.08093</td></tr><tr><td>precision</td><td>0.087</td></tr><tr><td>recall</td><td>0.40973</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-1</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/3w5lkobh' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/3w5lkobh</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_200824-3w5lkobh\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 9u4zx6l2 with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: RNN\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_204123-9u4zx6l2</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/9u4zx6l2' target=\"_blank\">young-sweep-2</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/9u4zx6l2' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/9u4zx6l2</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train\n",
      "epoch: time 0:02:58.030511\n",
      "loss:  0.08349160069193527\n",
      "test\n",
      "loss:  0.08332483526670707 acc:  0.16910377358490566\n",
      "epoch 1\n",
      "train\n",
      "epoch: time 0:02:46.959632\n",
      "loss:  0.08309070932671421\n",
      "test\n",
      "loss:  0.08301665463818694 acc:  0.16774764150943397\n",
      "epoch 2\n",
      "train\n",
      "epoch: time 0:02:46.034413\n",
      "loss:  0.0827530162567751\n",
      "test\n",
      "loss:  0.08323080001293488 acc:  0.16774764150943397\n",
      "epoch 3\n",
      "train\n",
      "epoch: time 0:02:46.935001\n",
      "loss:  0.08167753834672206\n",
      "test\n",
      "loss:  0.08359477557944801 acc:  0.16633254716981133\n",
      "epoch 4\n",
      "train\n",
      "epoch: time 0:02:46.660034\n",
      "loss:  0.08005592570207168\n",
      "test\n",
      "loss:  0.0846984087296252 acc:  0.1627948113207547\n",
      "epoch 5\n",
      "train\n",
      "epoch: time 0:02:46.373402\n",
      "loss:  0.07831016273092561\n",
      "test\n",
      "loss:  0.08620909221892087 acc:  0.1623820754716981\n",
      "epoch 6\n",
      "train\n",
      "epoch: time 0:02:46.160829\n",
      "loss:  0.07665854128489111\n",
      "test\n",
      "loss:  0.08789176797529437 acc:  0.15112028301886793\n",
      "epoch 7\n",
      "train\n",
      "epoch: time 0:02:46.556659\n",
      "loss:  0.0749605188775304\n",
      "test\n",
      "loss:  0.0900976077987338 acc:  0.1504127358490566\n",
      "epoch 8\n",
      "train\n",
      "epoch: time 0:02:46.357497\n",
      "loss:  0.07337473389208737\n",
      "test\n",
      "loss:  0.09172091611994887 acc:  0.1564858490566038\n",
      "epoch 9\n",
      "train\n",
      "epoch: time 0:02:46.096788\n",
      "loss:  0.07160467978740603\n",
      "test\n",
      "loss:  0.09274732112041059 acc:  0.15306603773584906\n",
      "error accured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f2bb121d3e142b19f126e4f4a3e8d2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>█▇▇▇▆▅▁▁▃▂</td></tr><tr><td>acc/train</td><td>▁▁▂▂▃▄▅▆▇█</td></tr><tr><td>acc_w</td><td>███▇▅▃▁▁▄▂</td></tr><tr><td>f1</td><td>▁▁▂▄▇█▇▇██</td></tr><tr><td>loss/test</td><td>▁▁▁▁▂▃▅▆▇█</td></tr><tr><td>loss/train</td><td>███▇▆▅▄▃▂▁</td></tr><tr><td>precision</td><td>▁▃▄▇██▇▇▇█</td></tr><tr><td>recall</td><td>███▇▅▃▁▁▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>0.15307</td></tr><tr><td>acc/train</td><td>0.50705</td></tr><tr><td>acc_w</td><td>0.38473</td></tr><tr><td>f1</td><td>0.12692</td></tr><tr><td>loss/test</td><td>0.09275</td></tr><tr><td>loss/train</td><td>0.0716</td></tr><tr><td>precision</td><td>0.08767</td></tr><tr><td>recall</td><td>0.38473</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-2</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/9u4zx6l2' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/9u4zx6l2</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_204123-9u4zx6l2\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: xrwr46cu with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_RNN\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_211348-xrwr46cu</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/xrwr46cu' target=\"_blank\">brisk-sweep-3</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/xrwr46cu' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/xrwr46cu</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4433a7b063754d87818177be4980d995"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-3</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/xrwr46cu' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/xrwr46cu</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_211348-xrwr46cu\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: zgu43epa with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_RNN\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_211441-zgu43epa</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/zgu43epa' target=\"_blank\">swept-sweep-4</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/zgu43epa' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/zgu43epa</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb8ed67d1a504855beae84038dfee823"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-4</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/zgu43epa' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/zgu43epa</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_211441-zgu43epa\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: sk9h6a3z with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_LSTM\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011277777777932999, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "351faf68d60545cd943d90c67ce749ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_211523-sk9h6a3z</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/sk9h6a3z' target=\"_blank\">quiet-sweep-5</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/sk9h6a3z' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/sk9h6a3z</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89ee9f58167848f08823dcaeed0255e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-5</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/sk9h6a3z' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/sk9h6a3z</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_211523-sk9h6a3z\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 75cqagc9 with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_LSTM\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_211616-75cqagc9</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/75cqagc9' target=\"_blank\">wild-sweep-6</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/75cqagc9' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/75cqagc9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d14a00a2915343b3bfa64a26e2c91cc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sweep-6</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/75cqagc9' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/75cqagc9</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_211616-75cqagc9\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 6jtkg44p with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: RNN\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_211710-6jtkg44p</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/6jtkg44p' target=\"_blank\">earthy-sweep-7</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/6jtkg44p' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/6jtkg44p</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train\n",
      "epoch: time 0:02:49.248092\n",
      "loss:  0.08333404958891663\n",
      "test\n",
      "loss:  0.08322261160669418 acc:  0.1658653846153846\n",
      "epoch 1\n",
      "train\n",
      "epoch: time 0:02:40.293553\n",
      "loss:  0.08312096006653473\n",
      "test\n",
      "loss:  0.08303884425415442 acc:  0.16598557692307692\n",
      "epoch 2\n",
      "train\n",
      "epoch: time 0:02:41.869750\n",
      "loss:  0.08305229062854443\n",
      "test\n",
      "loss:  0.08312416496471717 acc:  0.1658653846153846\n",
      "epoch 3\n",
      "train\n",
      "epoch: time 0:02:43.442932\n",
      "loss:  0.08302234863279648\n",
      "test\n",
      "loss:  0.0830865266517951 acc:  0.16580528846153847\n",
      "epoch 4\n",
      "train\n",
      "epoch: time 0:02:43.640767\n",
      "loss:  0.08295472963371685\n",
      "test\n",
      "loss:  0.0830870842990967 acc:  0.1655048076923077\n",
      "epoch 5\n",
      "train\n",
      "epoch: time 0:02:43.908781\n",
      "loss:  0.08283026975842332\n",
      "test\n",
      "loss:  0.08317024266490569 acc:  0.16592548076923078\n",
      "epoch 6\n",
      "train\n",
      "epoch: time 0:02:43.624926\n",
      "loss:  0.08265901496008239\n",
      "test\n",
      "loss:  0.08312635168146629 acc:  0.16532451923076924\n",
      "epoch 7\n",
      "train\n",
      "epoch: time 0:02:43.935222\n",
      "loss:  0.08236230386424659\n",
      "test\n",
      "loss:  0.08318184985277745 acc:  0.16544471153846155\n",
      "epoch 8\n",
      "train\n",
      "epoch: time 0:02:43.998348\n",
      "loss:  0.08198157091573195\n",
      "test\n",
      "loss:  0.08322006677492307 acc:  0.16568509615384616\n",
      "epoch 9\n",
      "train\n",
      "epoch: time 0:02:44.095823\n",
      "loss:  0.08152424160841559\n",
      "test\n",
      "loss:  0.08331509414487161 acc:  0.16532451923076924\n",
      "error accured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91ff7d4cf80740f4884e4f70f739bec0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>▇█▇▆▃▇▁▂▅▁</td></tr><tr><td>acc/train</td><td>▁▃▃▃▃▄▄▅▆█</td></tr><tr><td>acc_w</td><td>▆▆▃▇▆█▆▄▁▃</td></tr><tr><td>f1</td><td>▁▂█▁▅▅▂▄█▄</td></tr><tr><td>loss/test</td><td>▆▁▃▂▂▄▃▅▆█</td></tr><tr><td>loss/train</td><td>█▇▇▇▇▆▅▄▃▁</td></tr><tr><td>precision</td><td>▁▃▃▂▄▆▄▅█▅</td></tr><tr><td>recall</td><td>▆▆▃▇▆█▆▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>0.16532</td></tr><tr><td>acc/train</td><td>0.42838</td></tr><tr><td>acc_w</td><td>0.40944</td></tr><tr><td>f1</td><td>0.10597</td></tr><tr><td>loss/test</td><td>0.08332</td></tr><tr><td>loss/train</td><td>0.08152</td></tr><tr><td>precision</td><td>0.07547</td></tr><tr><td>recall</td><td>0.40944</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-7</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/6jtkg44p' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/6jtkg44p</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_211710-6jtkg44p\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: mqh7g1kx with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: RNN\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_214855-mqh7g1kx</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/mqh7g1kx' target=\"_blank\">breezy-sweep-8</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/mqh7g1kx' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/mqh7g1kx</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train\n",
      "epoch: time 0:02:50.976791\n",
      "loss:  0.08355111013132642\n",
      "test\n",
      "loss:  0.08330046706474745 acc:  0.16604567307692308\n",
      "epoch 1\n",
      "train\n",
      "epoch: time 0:02:40.721258\n",
      "loss:  0.08316440253577512\n",
      "test\n",
      "loss:  0.08317138544068886 acc:  0.1655048076923077\n",
      "epoch 2\n",
      "train\n",
      "epoch: time 0:02:42.653858\n",
      "loss:  0.08269176654331743\n",
      "test\n",
      "loss:  0.08333743984022966 acc:  0.16556490384615385\n",
      "epoch 3\n",
      "train\n",
      "epoch: time 0:02:42.947256\n",
      "loss:  0.08131030673114673\n",
      "test\n",
      "loss:  0.08446704116291724 acc:  0.16075721153846154\n",
      "epoch 4\n",
      "train\n",
      "epoch: time 0:02:43.153797\n",
      "loss:  0.07971092071848959\n",
      "test\n",
      "loss:  0.08544180221282519 acc:  0.16021634615384617\n",
      "epoch 5\n",
      "train\n",
      "epoch: time 0:02:43.422769\n",
      "loss:  0.07797907485185109\n",
      "test\n",
      "loss:  0.08674686340471872 acc:  0.15745192307692307\n",
      "epoch 6\n",
      "train\n",
      "epoch: time 0:02:43.252219\n",
      "loss:  0.07625023849422895\n",
      "test\n",
      "loss:  0.08828878991592388 acc:  0.15985576923076922\n",
      "epoch 7\n",
      "train\n",
      "epoch: time 0:02:43.132937\n",
      "loss:  0.07439368664539078\n",
      "test\n",
      "loss:  0.0904531877917739 acc:  0.14501201923076923\n",
      "epoch 8\n",
      "train\n",
      "epoch: time 0:02:42.988786\n",
      "loss:  0.0724140558724297\n",
      "test\n",
      "loss:  0.09268091137592609 acc:  0.1501201923076923\n",
      "epoch 9\n",
      "train\n",
      "epoch: time 0:02:43.153615\n",
      "loss:  0.07033423379049306\n",
      "test\n",
      "loss:  0.09357113597484736 acc:  0.1485576923076923\n",
      "error accured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3211121cf87a4f36921097cfcc4eda5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>███▆▆▅▆▁▃▂</td></tr><tr><td>acc/train</td><td>▁▁▂▃▃▄▅▆▇█</td></tr><tr><td>acc_w</td><td>███▅▅▅▆▂▃▁</td></tr><tr><td>f1</td><td>▁▂▂▆▅▆▅█▇█</td></tr><tr><td>loss/test</td><td>▁▁▁▂▃▃▄▆▇█</td></tr><tr><td>loss/train</td><td>███▇▆▅▄▃▂▁</td></tr><tr><td>precision</td><td>▁▂█▅▄▅▅▅▅▅</td></tr><tr><td>recall</td><td>███▅▅▅▆▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc/test</td><td>0.14856</td></tr><tr><td>acc/train</td><td>0.5185</td></tr><tr><td>acc_w</td><td>0.37013</td></tr><tr><td>f1</td><td>0.1322</td></tr><tr><td>loss/test</td><td>0.09357</td></tr><tr><td>loss/train</td><td>0.07033</td></tr><tr><td>precision</td><td>0.08763</td></tr><tr><td>recall</td><td>0.37013</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-8</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/mqh7g1kx' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/mqh7g1kx</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_214855-mqh7g1kx\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: l7hjwu0k with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_RNN\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_222038-l7hjwu0k</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/l7hjwu0k' target=\"_blank\">radiant-sweep-9</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/l7hjwu0k' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/l7hjwu0k</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.28431190961289127, max=1.…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39acaf06527e42e9bb21a39218f489e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-9</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/l7hjwu0k' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/l7hjwu0k</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_222038-l7hjwu0k\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: w3t1qznp with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_RNN\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_222121-w3t1qznp</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/w3t1qznp' target=\"_blank\">valiant-sweep-10</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/w3t1qznp' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/w3t1qznp</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.2843645794738792, max=1.0…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "179958f691f14fb781d2bef23892acad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-sweep-10</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/w3t1qznp' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/w3t1qznp</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_222121-w3t1qznp\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: g1hd30ip with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_LSTM\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_222203-g1hd30ip</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/g1hd30ip' target=\"_blank\">solar-sweep-11</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/g1hd30ip' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/g1hd30ip</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec7fcd583bc14fe4b3453d4c9710324d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-11</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/g1hd30ip' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/g1hd30ip</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_222203-g1hd30ip\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 4skzpax9 with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: wsd2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: After_Model_LSTM\n",
      "wandb: \toptLr: 0.0001\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240508_222257-4skzpax9</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/4skzpax9' target=\"_blank\">prime-sweep-12</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/wogrht6r</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/4skzpax9' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/4skzpax9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18e4cc7acde44b30958dcb57ca48b14a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-12</strong> at: <a href='https://wandb.ai/my_own_opt/AML/runs/4skzpax9' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/4skzpax9</a><br/> View project at: <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240508_222257-4skzpax9\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": "print('Hello world')",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T17:23:49.488280Z",
     "start_time": "2024-05-08T17:23:49.472574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T17:23:49.498801Z",
     "start_time": "2024-05-08T17:23:49.495269Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 51
  }
 ]
}

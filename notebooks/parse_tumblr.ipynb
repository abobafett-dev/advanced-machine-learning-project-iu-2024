{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# https://github.com/boilingpenguin/tumblr-scraper\n",
    "# https://github.com/tumblr/docs/blob/master/api.md"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:56:38.416643Z",
     "start_time": "2024-03-31T21:56:38.413490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pytumblr\n",
    "import calendar\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:56:38.809433Z",
     "start_time": "2024-03-31T21:56:38.417765Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../api_key.keys') as f:\n",
    "\tapi_key = f.readline()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:56:38.813429Z",
     "start_time": "2024-03-31T21:56:38.810581Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affectionate: ['affectionate']\n",
      "copypasta: ['copypasta', 'copypaste', 'repeated text']\n",
      "clickbait: ['clickbait']\n",
      "fake: ['fake']\n",
      "genuine: ['genuine']\n",
      "genuine question: ['genuine question']\n",
      "half joking: ['half joking', 'half-joking', 'half joke', 'half-joke', 'halfjoke']\n",
      "hyperbole: ['hyperbole']\n",
      "inside joke: ['inside joke', 'insidejoke', 'insidejoking', 'inside-joke', 'inside-joking']\n",
      "joking: ['joking', 'joke']\n",
      "lyrics: ['lyrics']\n",
      "light-hearted: ['light-hearted', 'light hearted', 'lighthearted']\n",
      "literal: ['literal', 'literally']\n",
      "little upset: ['little upset', 'littleupset', 'little-upset']\n",
      "metaphorical: ['metaphorical']\n",
      "not a vent: ['not a vent', 'notavent', 'not-a-vent']\n",
      "nobody here: ['nobodyhere', 'nobody-here']\n",
      "negative connotation: ['negative connotation', 'negetiveconnotation', 'negative-connotation']\n",
      "neutral connotation: ['neutral connotation', 'neutralconnotation', 'neutral-connotation']\n",
      "not forced: ['not forced', 'not-forced', 'notforced']\n",
      "not mad: ['not mad', 'not-mad', 'notmad']\n",
      "not passive aggressive: ['not passive aggressive', 'not passive-aggressive', 'not-passive-aggressive', 'notpassiveaggressive']\n",
      "not subtweeting: ['not subtweeting', 'notsubtweeting']\n",
      "non-serious: ['non-serious', 'non serious', 'nonserious', 'not serious', 'not-serious', 'notserious']\n",
      "non-sexual intent: ['non-sexual intent', 'not-sexual intent', 'non-sexual-intent', 'nonsexualintent', 'not-sexual-intent', 'notsexualintent']\n",
      "platonic: ['platonic']\n",
      "passive aggressive: ['passive aggressive', 'passive-aggressive']\n",
      "positive connotation: ['positive connotation', 'positive-connotation', 'positiveconnotation']\n",
      "quote: ['quote']\n",
      "romantic: ['romantic']\n",
      "reference: ['reference']\n",
      "rhetorical: ['rhetorical', 'rhetorical question', 'rhetorical-question', 'rhetoricalquestion']\n",
      "sarcastic: ['sarcastic', 'sarcasm']\n",
      "serious: ['serious']\n",
      "sexual intent: ['sexual intent', ' sexualintent', 'sexual-intent']\n",
      "teasing: ['teasing']\n",
      "threat: ['threat']\n",
      "ironic: ['ironic']\n",
      "not at you: ['not at you', 'not-at-you', 'notatyou']\n",
      "nothing personal: ['nothing personal', 'nothing-personal', 'nothingpersonal']\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../tonetags.txt\"\n",
    "\n",
    "tone_tags = {}\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "\tfor line in file:\n",
    "\t\tkey, value = line.strip().split(':')\n",
    "\t\ttone_tags[key.strip()] = value.strip().split(',')\n",
    "\n",
    "\n",
    "for key, values in tone_tags.items():\n",
    "\ttone_tags[key] = [item for item in tone_tags[key] if '/' not in item]\n",
    "\n",
    "for key, values in tone_tags.items():\n",
    "\tprint(f\"{key}: {values}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:56:38.819608Z",
     "start_time": "2024-03-31T21:56:38.814443Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of parsing affectionate\n",
      "API calls limit reached\n",
      "Current tag: affectionate\n",
      "Sleep for 3600 seconds to try again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/3601 [00:13<1:04:52,  1.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 49\u001B[0m\n\u001B[0;32m     47\u001B[0m \t\u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSleep for 3600 seconds to try again\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     48\u001B[0m \t\u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3601\u001B[39m)):\n\u001B[1;32m---> 49\u001B[0m \t\ttime\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_of_query \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m:\n\u001B[0;32m     52\u001B[0m \t\u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of query: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_of_query\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "tumblr = pytumblr.TumblrRestClient(api_key)\n",
    "tumblr_filter = 'text'\n",
    "start_time_search = calendar.timegm(time.gmtime())\n",
    "\n",
    "output_path = '../datasets/data_from_tumblr/'\n",
    "file_path = output_path + 'TumblrSearch'\n",
    "tumblr_df = pd.DataFrame(columns=['timestamp', 'URL', 'blogName', 'title', 'tags', 'text'])\n",
    "num_of_query = 1\n",
    "api_limit_reached = False\n",
    "\n",
    "for tag, tags in tone_tags.items():\n",
    "\toldest_time = start_time_search\n",
    "\tfor tone_tag in tags:\n",
    "\t\tresults = []\n",
    "\t\tprint(f\"Start of parsing {tone_tag}\\n\")\n",
    "\t\twhile True:\n",
    "\t\t\tsearchResults = tumblr.tagged(tone_tag, filter=tumblr_filter, before=oldest_time)\n",
    "\t\t\tfor post in searchResults:\n",
    "\t\t\t\tif post == 'meta':\n",
    "\t\t\t\t\tprint(\"API calls limit reached\")\n",
    "\t\t\t\t\tprint(f\"Current tag: {tone_tag}\")\n",
    "\t\t\t\t\tapi_limit_reached = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tblog_name = post['blog_name']\n",
    "\t\t\t\tdate = post['date']\n",
    "\t\t\t\turl = post['post_url']\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\ttitle = post['title']\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\ttitle = \"Couldn't Get Title\"\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\ttags = post['tags']\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\ttags = \"Couldn't Get tags\"\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tbody = post['body']\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tbody = \"Couldn't Get Post Body\"\n",
    "\t\t\t\tresults.append((date, url, blog_name, title, tags, body))\n",
    "\t\t\t\toldest_time = post['timestamp']\n",
    "\n",
    "\t\t\tif api_limit_reached:\n",
    "\t\t\t\tresults_df = pd.DataFrame(results, columns=['timestamp', 'URL', 'blogName', 'title', 'tags', 'text'])\n",
    "\t\t\t\ttumblr_df = pd.concat([tumblr_df, results_df])\n",
    "\t\t\t\ttumblr_df = tumblr_df.to_csv(file_path + '-' + str(time.time()) + '.csv')\n",
    "\t\t\t\tresults = []\n",
    "\t\t\t\tprint(\"Sleep for 3600 seconds to try again\")\n",
    "\t\t\t\tfor _ in tqdm(range(3601)):\n",
    "\t\t\t\t\ttime.sleep(1)\n",
    "\t\t\t\n",
    "\t\t\tif num_of_query % 10:\n",
    "\t\t\t\tprint(f\"Number of query: {num_of_query}\")\n",
    "\t\t\t\t\n",
    "\t\t\tnum_of_query += 1\n",
    "\t\t\t\n",
    "\t\t\tif len(searchResults) < 20:\n",
    "\t\t\t\tprint(f\"End of tag {tone_tag}\\n\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tresults_df = pd.DataFrame(results, columns=['timestamp', 'URL', 'blogName', 'title', 'tags', 'text'])\n",
    "\t\ttumblr_df = pd.concat([tumblr_df, results_df])\n",
    "\t\ttumblr_df = tumblr_df.to_csv(file_path + '-' + str(time.time()) + '.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:56:52.784612Z",
     "start_time": "2024-03-31T21:56:38.819608Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

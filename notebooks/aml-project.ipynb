{
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 8216013,
     "sourceType": "datasetVersion",
     "datasetId": 4816660
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install torchtext\n",
    "is_kaggle = False\n",
    "working_dir = '/kaggle/input/aml-dataset' if is_kaggle else '../datasets'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:38.388309Z",
     "iopub.execute_input": "2024-05-06T00:05:38.388714Z",
     "iopub.status.idle": "2024-05-06T00:05:38.393331Z",
     "shell.execute_reply.started": "2024-05-06T00:05:38.388687Z",
     "shell.execute_reply": "2024-05-06T00:05:38.392314Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:07.246693Z",
     "start_time": "2024-05-06T21:13:07.239709Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": "## Todo:\n- Переписать метрики\n- Перебор hyperparameters\n\n## Пути улучшения\n- Провести эксперименты со всеми датасетами\n- Модификация RNN, LSTM\n- Взять модель с Hugging Face\n- Изменить embedings (larger Glove, twiter glove, trainable glove)\n- Перебор hyperparameters\n    > lr",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"wanb\")\n",
    "secret_value_0 = \"write_your_secret_wandb_key\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:42.848927Z",
     "iopub.execute_input": "2024-05-06T00:05:42.849253Z",
     "iopub.status.idle": "2024-05-06T00:05:43.189116Z",
     "shell.execute_reply.started": "2024-05-06T00:05:42.849223Z",
     "shell.execute_reply": "2024-05-06T00:05:43.188149Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:11.023894Z",
     "start_time": "2024-05-06T21:13:07.247692Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: shalagin-danil (my_own_opt). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\89123\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.190344Z",
     "iopub.execute_input": "2024-05-06T00:05:43.190685Z",
     "iopub.status.idle": "2024-05-06T00:05:43.196825Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.190653Z",
     "shell.execute_reply": "2024-05-06T00:05:43.195849Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.138756Z",
     "start_time": "2024-05-06T21:13:11.029888Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "## Text preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def str_to_list(value):\n    list_values = value.strip('[]').split(', ')\n    cleaned_list_values = [item[1:-1] for item in list_values]\n    return cleaned_list_values",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.198101Z",
     "iopub.execute_input": "2024-05-06T00:05:43.198929Z",
     "iopub.status.idle": "2024-05-06T00:05:43.208526Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.198904Z",
     "shell.execute_reply": "2024-05-06T00:05:43.207636Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.143918Z",
     "start_time": "2024-05-06T21:13:14.140755Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "def str_context_to_list(value):\n    list_values = value.strip('[]').split(' ')\n    cleaned_list_values = []\n    for item in list_values:\n        item.strip()\n        # if '\\n' in item:\n        #     item.replace('\\n', '')\n        if item != \"\":\n            cleaned_list_values.append(float(item))\n    return cleaned_list_values",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.209553Z",
     "iopub.execute_input": "2024-05-06T00:05:43.209807Z",
     "iopub.status.idle": "2024-05-06T00:05:43.218931Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.209785Z",
     "shell.execute_reply": "2024-05-06T00:05:43.218076Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.154907Z",
     "start_time": "2024-05-06T21:13:14.144917Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "# dataset = pd.read_csv(\"../datasets/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset.tags.nunique()/len(dataset)\n# labels = dataset1.tags.unique().tolist()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.220040Z",
     "iopub.execute_input": "2024-05-06T00:05:43.220299Z",
     "iopub.status.idle": "2024-05-06T00:05:43.230910Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.220277Z",
     "shell.execute_reply": "2024-05-06T00:05:43.230185Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.162718Z",
     "start_time": "2024-05-06T21:13:14.155907Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "max_length = 2048\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.231868Z",
     "iopub.execute_input": "2024-05-06T00:05:43.232130Z",
     "iopub.status.idle": "2024-05-06T00:05:43.240382Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.232108Z",
     "shell.execute_reply": "2024-05-06T00:05:43.239650Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.167603Z",
     "start_time": "2024-05-06T21:13:14.163711Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_6b():\n",
    "    embeding_object = torchtext.vocab.GloVe('6B', dim=50)\n",
    "    vec_6 = embeding_object.vectors.numpy()\n",
    "    vec_6 = np.append(vec_6, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_6 = np.append(vec_6, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_6 = embeding_object.stoi\n",
    "    vocab_6[\"<unk>\"] = len(vocab_6)\n",
    "    vocab_6[\"<pad>\"] = len(vocab_6)\n",
    "\n",
    "    embed_tensor_6 = torch.tensor(vec_6, dtype=torch.float)\n",
    "    embed_glove_6 = nn.Embedding.from_pretrained(embed_tensor_6, freeze=True)\n",
    "\n",
    "    embed_size_6 = len(vocab_6)\n",
    "\n",
    "    return embed_glove_6, vocab_6, embed_size_6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.243684Z",
     "iopub.execute_input": "2024-05-06T00:05:43.243960Z",
     "iopub.status.idle": "2024-05-06T00:05:43.251553Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.243937Z",
     "shell.execute_reply": "2024-05-06T00:05:43.250731Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.175055Z",
     "start_time": "2024-05-06T21:13:14.168599Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, dataset, vocab=None):\n",
    "        if vocab is None:\n",
    "            _, vocab, _ = get_glove_6b()\n",
    "        self.data = []\n",
    "\n",
    "        for sentence in dataset.text:\n",
    "            if len(sentence) > max_length:\n",
    "                continue\n",
    "            sentence_ids = []\n",
    "            for token in sentence:\n",
    "                try:\n",
    "                    sentence_ids.append(vocab[token])\n",
    "                except KeyError:\n",
    "                    sentence_ids.append(vocab[\"<unk>\"])\n",
    "            self.data.append(sentence_ids)\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        self.labels = dataset.tags\n",
    "\n",
    "        self.context = None\n",
    "\n",
    "        if 'context' in dataset.columns:\n",
    "            self.context = dataset.context\n",
    "        #     self.context = self.context[:1000]\n",
    "        #     \n",
    "        # self.data = self.data[:1000]\n",
    "        # self.labels = self.labels[:1000]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.context is None:\n",
    "            return self.data[idx], torch.tensor(self.labels.iloc[idx])\n",
    "        else:\n",
    "            return self.data[idx], torch.tensor(self.labels.iloc[idx]), self.context.iloc[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.252562Z",
     "iopub.execute_input": "2024-05-06T00:05:43.252814Z",
     "iopub.status.idle": "2024-05-06T00:05:43.262796Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.252793Z",
     "shell.execute_reply": "2024-05-06T00:05:43.261887Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.184480Z",
     "start_time": "2024-05-06T21:13:14.178050Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "vocab_collate_fn = None\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    global vocab_collate_fn\n",
    "    vocab = vocab_collate_fn\n",
    "    data_ids = []\n",
    "    labels = []\n",
    "    for dat in batch:\n",
    "        data_ids.append(dat[0])\n",
    "        labels.append(dat[1])\n",
    "\n",
    "    for i in range(len(data_ids)):\n",
    "        while len(data_ids[i]) < max_length:\n",
    "            data_ids[i].append(vocab[\"<pad>\"])\n",
    "\n",
    "    return data_ids, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.263849Z",
     "iopub.execute_input": "2024-05-06T00:05:43.264130Z",
     "iopub.status.idle": "2024-05-06T00:05:43.278455Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.264108Z",
     "shell.execute_reply": "2024-05-06T00:05:43.277633Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.191005Z",
     "start_time": "2024-05-06T21:13:14.185484Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "# vec = torchtext.vocab.GloVe('6B', dim=50).vectors.numpy()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.279480Z",
     "iopub.execute_input": "2024-05-06T00:05:43.279719Z",
     "iopub.status.idle": "2024-05-06T00:05:43.288870Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.279699Z",
     "shell.execute_reply": "2024-05-06T00:05:43.288147Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.196134Z",
     "start_time": "2024-05-06T21:13:14.192006Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_6b():\n",
    "    embeding_object = torchtext.vocab.GloVe('6B', dim=50)\n",
    "    vec_6 = embeding_object.vectors.numpy()\n",
    "    vec_6 = np.append(vec_6, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_6 = np.append(vec_6, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_6 = embeding_object.stoi\n",
    "    vocab_6[\"<unk>\"] = len(vocab_6)\n",
    "    vocab_6[\"<pad>\"] = len(vocab_6)\n",
    "\n",
    "    embed_tensor_6 = torch.tensor(vec_6, dtype=torch.float)\n",
    "    embed_glove_6 = nn.Embedding.from_pretrained(embed_tensor_6, freeze=True)\n",
    "\n",
    "    embed_size_6 = len(vocab_6)\n",
    "\n",
    "    return embed_glove_6, vocab_6, embed_size_6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.289984Z",
     "iopub.execute_input": "2024-05-06T00:05:43.290247Z",
     "iopub.status.idle": "2024-05-06T00:05:43.299790Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.290225Z",
     "shell.execute_reply": "2024-05-06T00:05:43.298902Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.203709Z",
     "start_time": "2024-05-06T21:13:14.197134Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_42b():\n",
    "    embeding_object = torchtext.vocab.GloVe('42B', dim=300)\n",
    "    vec_840 = embeding_object.vectors.numpy()\n",
    "    vec_840 = np.append(vec_840, np.zeros(300)).reshape(-1, 300)\n",
    "    vec_840 = np.append(vec_840, np.ones(300)).reshape(-1, 300)\n",
    "\n",
    "    vocab_840 = embeding_object.stoi\n",
    "    vocab_840[\"<unk>\"] = len(vocab_840)\n",
    "    vocab_840[\"<pad>\"] = len(vocab_840)\n",
    "\n",
    "    embed_tensor = torch.tensor(vec_840, dtype=torch.float)\n",
    "    embed_glove_840 = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "\n",
    "    embed_size_840 = len(vec_840)\n",
    "\n",
    "    return embed_glove_840, vocab_840, embed_size_840"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.300942Z",
     "iopub.execute_input": "2024-05-06T00:05:43.301719Z",
     "iopub.status.idle": "2024-05-06T00:05:43.313229Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.301689Z",
     "shell.execute_reply": "2024-05-06T00:05:43.312392Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.210421Z",
     "start_time": "2024-05-06T21:13:14.204709Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def get_glove_twitter():\n",
    "    embeding_object = torchtext.vocab.GloVe('twitter.27B', dim=50)\n",
    "    vec_twitter = embeding_object.vectors.numpy()\n",
    "    vec_twitter = np.append(vec_twitter, np.zeros(50)).reshape(-1, 50)\n",
    "    vec_twitter = np.append(vec_twitter, np.ones(50)).reshape(-1, 50)\n",
    "\n",
    "    vocab_twitter = embeding_object.stoi\n",
    "    vocab_twitter[\"<unk>\"] = len(vocab_twitter)\n",
    "    vocab_twitter[\"<pad>\"] = len(vocab_twitter)\n",
    "\n",
    "    embed_tensor = torch.tensor(vec_twitter, dtype=torch.float)\n",
    "    embed_glove_twitter = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "\n",
    "    embed_size_twitter = len(vec_twitter)\n",
    "\n",
    "    return embed_glove_twitter, vocab_twitter, embed_size_twitter"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.314366Z",
     "iopub.execute_input": "2024-05-06T00:05:43.314624Z",
     "iopub.status.idle": "2024-05-06T00:05:43.323785Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.314603Z",
     "shell.execute_reply": "2024-05-06T00:05:43.323024Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.216893Z",
     "start_time": "2024-05-06T21:13:14.211421Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": "## WSD 1",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# # dataset = pd.read_csv(\"../datasets/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset_wsd_1 = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n# labels = dataset_wsd_1.tags.unique().tolist()\n# dataset_wsd_1.tags = dataset_wsd_1.tags.apply(labels.index)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.324970Z",
     "iopub.execute_input": "2024-05-06T00:05:43.325264Z",
     "iopub.status.idle": "2024-05-06T00:05:43.334553Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.325241Z",
     "shell.execute_reply": "2024-05-06T00:05:43.333792Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.222237Z",
     "start_time": "2024-05-06T21:13:14.217894Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "# dataset_wsd_1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.335509Z",
     "iopub.execute_input": "2024-05-06T00:05:43.335763Z",
     "iopub.status.idle": "2024-05-06T00:05:43.348685Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.335741Z",
     "shell.execute_reply": "2024-05-06T00:05:43.348005Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.226874Z",
     "start_time": "2024-05-06T21:13:14.223236Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "# train, test = train_test_split(dataset_wsd_1, test_size=0.2, shuffle=True,stratify=dataset_wsd_1.tags)\n\n# train_dataset1 = myDataset(train)\n# test_dataset1 = myDataset(test)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.349760Z",
     "iopub.execute_input": "2024-05-06T00:05:43.350040Z",
     "iopub.status.idle": "2024-05-06T00:05:43.357851Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.350017Z",
     "shell.execute_reply": "2024-05-06T00:05:43.357090Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.232150Z",
     "start_time": "2024-05-06T21:13:14.227874Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def wsd1_creator(embeding):\n",
    "    dataset_wsd_1 = pd.read_csv(f\"{working_dir}/tonetags_wsd_1.csv\", index_col=0, converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_wsd_1.tags.unique().tolist()\n",
    "    dataset_wsd_1.tags = dataset_wsd_1.tags.apply(labels.index)\n",
    "\n",
    "    train, test = train_test_split(dataset_wsd_1, test_size=0.2, shuffle=True, stratify=dataset_wsd_1.tags)\n",
    "\n",
    "    train, test = myDataset(train, embeding), myDataset(test, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.358675Z",
     "iopub.execute_input": "2024-05-06T00:05:43.358899Z",
     "iopub.status.idle": "2024-05-06T00:05:43.368508Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.358879Z",
     "shell.execute_reply": "2024-05-06T00:05:43.367801Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.238808Z",
     "start_time": "2024-05-06T21:13:14.233151Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader1 = DataLoader(train_dataset1, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n# test_dataloader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.369468Z",
     "iopub.execute_input": "2024-05-06T00:05:43.369721Z",
     "iopub.status.idle": "2024-05-06T00:05:43.378294Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.369700Z",
     "shell.execute_reply": "2024-05-06T00:05:43.377468Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.244123Z",
     "start_time": "2024-05-06T21:13:14.239809Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": "# for batch in tqdm(train_dataloader):\n#     embedded_tokens = batch[0]\n#     labels = batch[1]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.379397Z",
     "iopub.execute_input": "2024-05-06T00:05:43.379683Z",
     "iopub.status.idle": "2024-05-06T00:05:43.387747Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.379652Z",
     "shell.execute_reply": "2024-05-06T00:05:43.386927Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.249473Z",
     "start_time": "2024-05-06T21:13:14.245123Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": "## WSD 2",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_wsd_2 = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_wsd_2.csv\", index_col=0, converters={\"text\": str_to_list})\n# dataset_wsd_2 = dataset_wsd_2.dropna()\n\n# labels = dataset_wsd_2.tags.unique().tolist()\n# dataset_wsd_2.tags = dataset_wsd_2.tags.apply(labels.index)\n\n# dataset_wsd_2.context = dataset_wsd_2.context.apply(str_context_to_list)\n\n# dataset_wsd_2.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.388766Z",
     "iopub.execute_input": "2024-05-06T00:05:43.389025Z",
     "iopub.status.idle": "2024-05-06T00:05:43.397392Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.389000Z",
     "shell.execute_reply": "2024-05-06T00:05:43.396704Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.254841Z",
     "start_time": "2024-05-06T21:13:14.250472Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "# train_wsd_2, test_wsd_2 = train_test_split(dataset_wsd_2, stratify=dataset_wsd_2['tags'], test_size=0.2, random_state=42)\n# train_dataset_wsd_2, test_dataset_wsd_2 = myDataset(train_wsd_2), myDataset(test_wsd_2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.398492Z",
     "iopub.execute_input": "2024-05-06T00:05:43.398776Z",
     "iopub.status.idle": "2024-05-06T00:05:43.406594Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.398748Z",
     "shell.execute_reply": "2024-05-06T00:05:43.405762Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.259835Z",
     "start_time": "2024-05-06T21:13:14.255842Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "def wsd2_creator(embeding):\n",
    "    dataset_wsd_2 = pd.read_csv(f\"{working_dir}/tonetags_wsd_2.csv\", index_col=0, converters={\"text\": str_to_list})\n",
    "    dataset_wsd_2 = dataset_wsd_2.dropna()\n",
    "\n",
    "    labels = dataset_wsd_2.tags.unique().tolist()\n",
    "    dataset_wsd_2.tags = dataset_wsd_2.tags.apply(labels.index)\n",
    "    dataset_wsd_2.context = dataset_wsd_2.context.apply(str_context_to_list)\n",
    "\n",
    "    train_wsd_2, test_wsd_2 = train_test_split(dataset_wsd_2, stratify=dataset_wsd_2['tags'], test_size=0.2,\n",
    "                                               random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_wsd_2, embeding), myDataset(test_wsd_2, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.407694Z",
     "iopub.execute_input": "2024-05-06T00:05:43.407962Z",
     "iopub.status.idle": "2024-05-06T00:05:43.420210Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.407933Z",
     "shell.execute_reply": "2024-05-06T00:05:43.419384Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.265811Z",
     "start_time": "2024-05-06T21:13:14.260828Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_wsd_2 = DataLoader(train_dataset_wsd_2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_wsd_2 = DataLoader(test_dataset_wsd_2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.421336Z",
     "iopub.execute_input": "2024-05-06T00:05:43.421572Z",
     "iopub.status.idle": "2024-05-06T00:05:43.430955Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.421552Z",
     "shell.execute_reply": "2024-05-06T00:05:43.430083Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.272581Z",
     "start_time": "2024-05-06T21:13:14.269801Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "## Clean_corrected dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_clean_corrected = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_dataset_tumblr_clean_corrected_text.csv\", converters={\"text\": str_to_list})\n\n# labels = dataset_clean_corrected.tags.unique().tolist()\n# dataset_clean_corrected.tags =dataset_clean_corrected.tags.apply(labels.index)\n\n# dataset_clean_corrected.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.432111Z",
     "iopub.execute_input": "2024-05-06T00:05:43.432383Z",
     "iopub.status.idle": "2024-05-06T00:05:43.441669Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.432361Z",
     "shell.execute_reply": "2024-05-06T00:05:43.440797Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.277212Z",
     "start_time": "2024-05-06T21:13:14.273563Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "# train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected, stratify=dataset_clean_corrected['tags'], test_size=0.2, random_state=42)\n# train_dataset_clean_corrected, test_dataset_clean_corrected = myDataset(train_clean_corrected), myDataset(test_clean_corrected)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.447641Z",
     "iopub.execute_input": "2024-05-06T00:05:43.448013Z",
     "iopub.status.idle": "2024-05-06T00:05:43.451951Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.447983Z",
     "shell.execute_reply": "2024-05-06T00:05:43.451140Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.281841Z",
     "start_time": "2024-05-06T21:13:14.278212Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_corrected_creator(embeding):\n",
    "    dataset_clean_corrected = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean_corrected_text.csv\",\n",
    "                                          converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean_corrected.tags.unique().tolist()\n",
    "    dataset_clean_corrected.tags = dataset_clean_corrected.tags.apply(labels.index)\n",
    "\n",
    "    train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected,\n",
    "                                                                   stratify=dataset_clean_corrected['tags'],\n",
    "                                                                   test_size=0.2, random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean_corrected, embeding), myDataset(test_clean_corrected, embeding)\n",
    "    train_dataloader_clean_corrected = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                  drop_last=True)\n",
    "    test_dataloader_clean_corrected = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                 drop_last=True)\n",
    "    return train_dataloader_clean_corrected, test_dataloader_clean_corrected"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.452959Z",
     "iopub.execute_input": "2024-05-06T00:05:43.453297Z",
     "iopub.status.idle": "2024-05-06T00:05:43.463461Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.453267Z",
     "shell.execute_reply": "2024-05-06T00:05:43.462619Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.288684Z",
     "start_time": "2024-05-06T21:13:14.282842Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_clean_corrected = DataLoader(train_dataset_clean_corrected, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_clean_corrected = DataLoader(test_dataset_clean_corrected, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.464546Z",
     "iopub.execute_input": "2024-05-06T00:05:43.464873Z",
     "iopub.status.idle": "2024-05-06T00:05:43.477726Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.464832Z",
     "shell.execute_reply": "2024-05-06T00:05:43.476772Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.292983Z",
     "start_time": "2024-05-06T21:13:14.289684Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": "## Clean",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# dataset_clean = pd.read_csv(\"/kaggle/input/aml-dataset/tonetags_dataset_tumblr_clean.csv\", converters={\"text\": str_to_list})\n\n# labels = dataset_clean.tags.unique().tolist()\n# dataset_clean.tags =dataset_clean.tags.apply(labels.index)\n\n# dataset_clean.head(5)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.478864Z",
     "iopub.execute_input": "2024-05-06T00:05:43.479179Z",
     "iopub.status.idle": "2024-05-06T00:05:43.487999Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.479156Z",
     "shell.execute_reply": "2024-05-06T00:05:43.487249Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.298004Z",
     "start_time": "2024-05-06T21:13:14.293984Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "# train_clean, test_clean = train_test_split(dataset_clean, stratify=dataset_clean['tags'], test_size=0.2, random_state=42)\n# train_dataset_clean, test_dataset_clean = myDataset(train_clean), myDataset(test_clean)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.488996Z",
     "iopub.execute_input": "2024-05-06T00:05:43.489252Z",
     "iopub.status.idle": "2024-05-06T00:05:43.499237Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.489231Z",
     "shell.execute_reply": "2024-05-06T00:05:43.498490Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.302738Z",
     "start_time": "2024-05-06T21:13:14.299004Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_creator(embeding):\n",
    "    dataset_clean = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean.csv\", converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean.tags.unique().tolist()\n",
    "    dataset_clean.tags = dataset_clean.tags.apply(labels.index)\n",
    "\n",
    "    train_clean, test_clean = train_test_split(dataset_clean, stratify=dataset_clean['tags'], test_size=0.2,\n",
    "                                               random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean, embeding), myDataset(test_clean, embeding)\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.500329Z",
     "iopub.execute_input": "2024-05-06T00:05:43.501203Z",
     "iopub.status.idle": "2024-05-06T00:05:43.509162Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.501171Z",
     "shell.execute_reply": "2024-05-06T00:05:43.508436Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.309017Z",
     "start_time": "2024-05-06T21:13:14.303738Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "# train_dataloader_clean = DataLoader(train_dataset_clean, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n# test_dataloader_clean = DataLoader(test_dataset_clean, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.510249Z",
     "iopub.execute_input": "2024-05-06T00:05:43.511074Z",
     "iopub.status.idle": "2024-05-06T00:05:43.522443Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.511050Z",
     "shell.execute_reply": "2024-05-06T00:05:43.521527Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.313719Z",
     "start_time": "2024-05-06T21:13:14.310019Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_corrected_wsd2_creator(embeding):\n",
    "    dataset_clean_corrected = pd.read_csv(f\"{working_dir}/tonetags_dataset_tumblr_clean_corrected_text_wsd_2.csv\",\n",
    "                                          converters={\"text\": str_to_list})\n",
    "\n",
    "    labels = dataset_clean_corrected.tags.unique().tolist()\n",
    "    dataset_clean_corrected.tags = dataset_clean_corrected.tags.apply(labels.index)\n",
    "\n",
    "    train_clean_corrected, test_clean_corrected = train_test_split(dataset_clean_corrected,\n",
    "                                                                   stratify=dataset_clean_corrected['tags'],\n",
    "                                                                   test_size=0.2, random_state=42)\n",
    "\n",
    "    train, test = myDataset(train_clean_corrected, embeding), myDataset(test_clean_corrected, embeding)\n",
    "    train_dataloader_clean_corrected = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                  drop_last=True)\n",
    "    test_dataloader_clean_corrected = DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                                                 drop_last=True)\n",
    "    return train_dataloader_clean_corrected, test_dataloader_clean_corrected\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.319905Z",
     "start_time": "2024-05-06T21:13:14.314720Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": "## Train utils",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "epoch_result = {}\n",
    "\n",
    "\n",
    "def update_result(d):\n",
    "    global epoch_result\n",
    "\n",
    "    for k in d.keys():\n",
    "        if k in list(epoch_result.keys()):\n",
    "            raise Exception\n",
    "\n",
    "    epoch_result.update(d)\n",
    "\n",
    "\n",
    "def log():\n",
    "    global epoch_result\n",
    "    wandb.log(epoch_result)\n",
    "    epoch_result.clear()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.523534Z",
     "iopub.execute_input": "2024-05-06T00:05:43.523814Z",
     "iopub.status.idle": "2024-05-06T00:05:43.533182Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.523784Z",
     "shell.execute_reply": "2024-05-06T00:05:43.532308Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:14.325317Z",
     "start_time": "2024-05-06T21:13:14.320905Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "import torchmetrics\n",
    "def train_epoch(trainloader, model, opt, loss_criterion):\n",
    "    global epoch_result\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    #loss для одной epoch\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    #применить для каждого бача из trainload\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    number_of_batches = len(list(trainloader))\n",
    "    result = []\n",
    "    result1 = []\n",
    "    for batch_idx, inputs_all in enumerate(trainloader):\n",
    "\n",
    "        inputs, targets, context = None, None, None\n",
    "        if len(inputs_all) == 2:\n",
    "            inputs, targets = inputs_all\n",
    "            inputs = torch.tensor(inputs)\n",
    "            targets = torch.tensor(targets)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        else:\n",
    "            inputs, targets, context = inputs_all\n",
    "            inputs = torch.tensor(inputs)\n",
    "            targets = torch.tensor(targets)\n",
    "            context = torch.tensor(context)\n",
    "            inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "        #тренировка\n",
    "        opt.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "\n",
    "        #шаг оптимизации/loss funct       \n",
    "        loss = loss_criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        predicted = outputs.argmax(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        #подсчет точности\n",
    "        total += targets.size(0)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        result.append(targets)\n",
    "        result1.append(outputs)\n",
    "\n",
    "    del context\n",
    "    del inputs\n",
    "    del targets\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # запись loss/acc для train в классе statistic, и в Tensorboard\n",
    "\n",
    "    #         print(\"epoch---------------\")\n",
    "    num_classes=19\n",
    "    accuracy_func = torchmetrics.classification.Accuracy(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                         top_k=3)\n",
    "    print(\"train\")\n",
    "    print(\"epoch: time\", datetime.datetime.now() - start_time)\n",
    "    print(\"loss: \", train_loss / total)\n",
    "\n",
    "    # update_result({\"loss/train\": train_loss / total, \"acc/train\": correct / total})\n",
    "    y_train,y_pred = torch.cat(result).reshape(-1).cpu(), torch.cat(result1).cpu()\n",
    "    update_result({\"loss/train\": train_loss / total, \"acc/train\": accuracy_func(y_pred,y_train)})\n",
    "    \n",
    "\n",
    "\n",
    "def test(testloader, model, loss_criterion):\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs_all in enumerate(testloader):\n",
    "\n",
    "            inputs, targets, context = None, None, None\n",
    "            if len(inputs_all) == 2:\n",
    "                inputs, targets = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            else:\n",
    "                inputs, targets, context = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                context = torch.tensor(context)\n",
    "                inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "\n",
    "            outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "            #             inputs, targets = inputs.to(device), targets.to(device)\n",
    "            #             logits = model(inputs)\n",
    "            #             outputs = torch.nn.functional.log_softmax(logits,dim=1)\n",
    "\n",
    "            loss = loss_criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            #             _, predicted = outputs.exp(dim=1).max(1)\n",
    "            predicted = outputs.argmax(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        del context\n",
    "        del inputs\n",
    "        del targets\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # запись loss/acc для test в классе statistic, и в Tensorboard\n",
    "    print('test')\n",
    "    print(\"loss: \", test_loss / total, \"acc: \", correct / total)\n",
    "    update_result({\"loss/test\": test_loss / total, \"acc/test\": correct / total})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.534631Z",
     "iopub.execute_input": "2024-05-06T00:05:43.534898Z",
     "iopub.status.idle": "2024-05-06T00:05:43.553840Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.534876Z",
     "shell.execute_reply": "2024-05-06T00:05:43.552892Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.341260Z",
     "start_time": "2024-05-06T21:13:14.326317Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "def inference(testloader, model):\n",
    "    global device\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "    result1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs_all in enumerate(testloader):\n",
    "            inputs, targets, context = None, None, None\n",
    "            if len(inputs_all) == 2:\n",
    "                inputs, targets = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            else:\n",
    "                inputs, targets, context = inputs_all\n",
    "                inputs = torch.tensor(inputs)\n",
    "                targets = torch.tensor(targets)\n",
    "                context = torch.tensor(context)\n",
    "                inputs, targets, context = inputs.to(device), targets.to(device), context.to(device)\n",
    "\n",
    "            outputs = model(inputs, context).reshape(len(inputs), -1)\n",
    "\n",
    "            predicted = torch.argmax(outputs, -1)\n",
    "\n",
    "            result.append(predicted)\n",
    "            result1.append(outputs)\n",
    "        del context\n",
    "        del inputs\n",
    "        del targets\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return torch.cat(result).reshape(-1).cpu(), torch.cat(result1).cpu()\n",
    "\n",
    "\n",
    "def get_targets(testloader):\n",
    "    result = []\n",
    "    for batch_idx, inputs_all in enumerate(testloader):\n",
    "        inputs, targets, context = None, None, None\n",
    "        if len(inputs_all) == 2:\n",
    "            inputs, targets = inputs_all\n",
    "            targets = torch.tensor(targets)\n",
    "        else:\n",
    "            inputs, targets, context = inputs_all\n",
    "            targets = torch.tensor(targets)\n",
    "        result.append(targets)\n",
    "    del context\n",
    "    del inputs\n",
    "    del targets\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(result).reshape(-1).cpu()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:21:43.104716Z",
     "iopub.execute_input": "2024-05-06T00:21:43.105503Z",
     "iopub.status.idle": "2024-05-06T00:21:43.116733Z",
     "shell.execute_reply.started": "2024-05-06T00:21:43.105473Z",
     "shell.execute_reply": "2024-05-06T00:21:43.115811Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.350434Z",
     "start_time": "2024-05-06T21:13:15.342259Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def train(epoch, trainloader, testloader, model, loss, opt):\n",
    "    global current_epoch_number\n",
    "    global total_epoch\n",
    "    total_epoch = epoch\n",
    "    for current_epoch_number in range(epoch):\n",
    "        print(\"epoch\", current_epoch_number)\n",
    "        train_epoch(trainloader=trainloader, model=model, opt=opt, loss_criterion=loss)\n",
    "        test(testloader=testloader, model=model, loss_criterion=loss)\n",
    "\n",
    "        outputs, y_scores = inference(model=model, testloader=testloader)\n",
    "        targets = get_targets(testloader=testloader)\n",
    "        evaluate(targets, outputs, y_scores)\n",
    "\n",
    "        log()\n",
    "    outputs,y_scores = inference(model=model, testloader=testloader)\n",
    "    targets = get_targets(testloader=testloader)\n",
    "    evaluate_final_stage(outputs, targets, y_scores)\n",
    "\n",
    "#         if scheduler is None:\n",
    "#             continue\n",
    "#         scheduler.step()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.628898Z",
     "iopub.status.idle": "2024-05-06T00:05:43.629254Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.629093Z",
     "shell.execute_reply": "2024-05-06T00:05:43.629107Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.360671Z",
     "start_time": "2024-05-06T21:13:15.351434Z"
    }
   },
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "# def evaluate(y_true,y_pred):\n",
    "#     from sklearn.metrics import f1_score\n",
    "#     from sklearn.metrics import precision_score\n",
    "#     from sklearn.metrics import recall_score\n",
    "\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#     if (y_true<0).all():\n",
    "#         return\n",
    "#     # Переписать\n",
    "#     # Добавить confusion matrix\n",
    "\n",
    "\n",
    "# #     result = {\"acc\": accuracy_score(y_pred_class,y_true),\n",
    "# #               }\n",
    "\n",
    "\n",
    "#     wandb.log(result,step=current_epoch_number)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.630487Z",
     "iopub.status.idle": "2024-05-06T00:05:43.630817Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.630657Z",
     "shell.execute_reply": "2024-05-06T00:05:43.630671Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.365072Z",
     "start_time": "2024-05-06T21:13:15.361671Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# \n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import top_k_accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred, y_scores=None):\n",
    "    num_classes = 19\n",
    "    accuracy_func = torchmetrics.classification.Accuracy(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                         top_k=3)\n",
    "    precision_func = torchmetrics.classification.Precision(task='multiclass', num_classes=num_classes,\n",
    "                                                           average='weighted', top_k=3)\n",
    "    recall_func = torchmetrics.classification.Recall(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                     top_k=3)\n",
    "    f1score_func = torchmetrics.classification.F1Score(task='multiclass', num_classes=num_classes, average='weighted',\n",
    "                                                       top_k=3)\n",
    "\n",
    "    # if (y_true<0).all():\n",
    "    #     return\n",
    "    # \n",
    "    # f1_one_vs_all = f1_score(y_pred,y_true,average=None)\n",
    "    # recall_one_vs_all = recall_score(y_pred,y_true,average=None)\n",
    "    # recall_one_vs_all = recall_score(y_pred,y_true,average=None)\n",
    "\n",
    "    result = {\"acc_w\": accuracy_func(y_scores, y_true),\n",
    "              \"precision\": precision_func(y_scores, y_true),\n",
    "              \"recall\": recall_func(y_scores, y_true),\n",
    "              \"f1\": f1score_func(y_scores, y_true)}\n",
    "\n",
    "    # result = {\"acc\": accuracy_score(y_true,y_pred),\n",
    "    #           \"f1_micro\":f1_score(y_true,y_pred,average='micro'),\n",
    "    #           \"precision_micro\": precision_score(y_true,y_pred,average='micro'),\n",
    "    #           \"recall_micro\":recall_score(y_true,y_pred,average='micro'),\n",
    "    #           \"top_k_acc\":top_k_accuracy_score(y_true,y_pred,k=3)\n",
    "    #           }\n",
    "    # result.update({f\"precision_one_vs_all_{i}\":val for i,val in enumerate(f1_one_vs_all)})\n",
    "    # result.update({f\"recall_one_vs_all_{i}\":val for i,val in enumerate(f1_one_vs_all)})\n",
    "\n",
    "    #     if y_scores is None:\n",
    "    #         update_result(result)\n",
    "    #         return \n",
    "\n",
    "    #     result.update({\"acc_top_k\":top_k_accuracy_score(y_true,y_scores,labels=range(20))})\n",
    "\n",
    "    update_result(result)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def evaluate_final_stage(y_true, y_pred, y_scores):\n",
    "    # print(result)\n",
    "    labels = range(20)\n",
    "    try:\n",
    "        table = wandb.Table(columns=[\"tag\", \"true_tag\", \"y_scores\"], data=torch.cat((y_pred, y_true, y_scores), dim=1))\n",
    "        pd.DataFrame(torch.cat((y_pred, y_true, y_scores), dim=1).numpy()).to_csv(time.time())\n",
    "    except:\n",
    "        print(\"error accured\")\n",
    "        table = -1\n",
    "\n",
    "    cm = wandb.plot.confusion_matrix(\n",
    "        y_true=y_true,\n",
    "        preds=y_pred,\n",
    "        class_names=labels)\n",
    "\n",
    "    wandb.log({\"conf_mat\": cm, \"predictions\": table})"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.632115Z",
     "iopub.status.idle": "2024-05-06T00:05:43.632430Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.632278Z",
     "shell.execute_reply": "2024-05-06T00:05:43.632291Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.375206Z",
     "start_time": "2024-05-06T21:13:15.366066Z"
    }
   },
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": "## Model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T19:35:29.839646Z",
     "start_time": "2024-04-14T19:35:29.83776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "# input_dim, hidden_dim, layer_dim, output_dim",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.634010Z",
     "iopub.status.idle": "2024-05-06T00:05:43.634321Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.634169Z",
     "shell.execute_reply": "2024-05-06T00:05:43.634182Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.380639Z",
     "start_time": "2024-05-06T21:13:15.375632Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTagsRNN(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100, rnn=True):\n",
    "        super(ToneTagsRNN, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                                bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "        if not (context is None):\n",
    "            embedded = torch.cat(embedded, context)\n",
    "            embedded = self.fc0(embedded)\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:11:41.340827Z",
     "iopub.execute_input": "2024-05-06T00:11:41.341483Z",
     "iopub.status.idle": "2024-05-06T00:11:41.356987Z",
     "shell.execute_reply.started": "2024-05-06T00:11:41.341452Z",
     "shell.execute_reply": "2024-05-06T00:11:41.356024Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.389100Z",
     "start_time": "2024-05-06T21:13:15.381618Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTagsLSTM(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100, rnn=False):\n",
    "        super(ToneTagsLSTM, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers,\n",
    "                                 bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "        if not (context is None):\n",
    "            embedded = torch.cat(embedded, context)\n",
    "            embedded = self.fc0(embedded)\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.638056Z",
     "iopub.status.idle": "2024-05-06T00:05:43.638503Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.638268Z",
     "shell.execute_reply": "2024-05-06T00:05:43.638286Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.397240Z",
     "start_time": "2024-05-06T21:13:15.390101Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTags_After_Model_RNN(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100):\n",
    "        super(ToneTags_After_Model_RNN, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.seq_layer = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim,\n",
    "                                      num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, 1024)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        output, hidden = self.seq_layer(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        # if not (context is None):\n",
    "        rnn_out = torch.cat(rnn_out, context)\n",
    "        rnn_out = self.fc4(rnn_out)\n",
    "\n",
    "        # fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(rnn_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.639727Z",
     "iopub.status.idle": "2024-05-06T00:05:43.640174Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.639933Z",
     "shell.execute_reply": "2024-05-06T00:05:43.639950Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.407375Z",
     "start_time": "2024-05-06T21:13:15.398240Z"
    }
   },
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "class ToneTags_After_Model_LSTM(torch.nn.Module):\n",
    "    def __init__(self, embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.2,\n",
    "                 embed_context_size=100):\n",
    "        super(ToneTags_After_Model_LSTM, self).__init__()\n",
    "        # vocab_size = 400002\n",
    "        # embedding_dim = 50\n",
    "        # hidden_dim_lstm = 30\n",
    "\n",
    "        # output_size = 19\n",
    "        self.rnn_output_size = hidden_dim * max_length * 2\n",
    "\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.seq_layer = torch.nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim,\n",
    "                                       num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        #         (64x6400 and 409600x1024)\n",
    "        #         50*4096*2\n",
    "        self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim * max_length * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, 1024)\n",
    "        # self.fc4 = nn.Linear(hidden_dim * max_length * 2 + embed_context_size, hidden_dim * max_length * 2)\n",
    "        # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        activation = torch.nn.ReLU()\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        output, hidden = self.seq_layer(embedded)\n",
    "\n",
    "        rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "        # if not (context is None):\n",
    "        rnn_out = torch.cat(rnn_out, context)\n",
    "        rnn_out = self.fc4(rnn_out)\n",
    "\n",
    "        fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "        fc2_out = activation(self.fc2(fc1_out))\n",
    "        out = self.fc3(fc2_out)\n",
    "        #         \n",
    "        return out\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.641468Z",
     "iopub.status.idle": "2024-05-06T00:05:43.641912Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.641681Z",
     "shell.execute_reply": "2024-05-06T00:05:43.641698Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.416067Z",
     "start_time": "2024-05-06T21:13:15.408375Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "# class ToneTagsRNN(torch.nn.Module):\n",
    "#     def __init__(self,embedding, vocab_size=400002, hidden_dim=50, output_size=19, num_layers=2, dropout=0.4,embed_context_size=100):\n",
    "#         super(ToneTagsRNN, self).__init__()\n",
    "#         # vocab_size = 400002\n",
    "#         # embedding_dim = 50\n",
    "#         # hidden_dim_lstm = 30\n",
    "\n",
    "#         # output_size = 19\n",
    "#         self.rnn_output_size = hidden_dim*max_length*2\n",
    "\n",
    "#         self.embedding = embedding\n",
    "#         self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "#         self.rnn = torch.nn.RNN(input_size=self.embedding.embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "# #         (64x6400 and 409600x1024)\n",
    "# #         50*4096*2\n",
    "#         self.fc0 = nn.Linear(embed_context_size, self.embedding.embedding_dim)\n",
    "#         self.fc1 = nn.Linear(hidden_dim*max_length*2, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, output_size)\n",
    "#         # self.out = nn.Softmax(output_size, dim=1)\n",
    "\n",
    "#     def forward(self,x,context=None):\n",
    "#         activation = torch.nn.ReLU()\n",
    "#         embedded = self.embedding(x)\n",
    "#         if not(context is None):\n",
    "#             embedded = torch.cat(embedded,context)\n",
    "#             embedded = self.fc0(embedded)\n",
    "\n",
    "#         output, hidden = self.rnn(embedded)\n",
    "\n",
    "#         rnn_out = output.reshape(-1, self.rnn_output_size)\n",
    "\n",
    "\n",
    "#         fc1_out = activation(self.fc1(rnn_out))\n",
    "\n",
    "#         fc2_out = activation(self.fc2(fc1_out))\n",
    "#         out = self.fc3(fc2_out)\n",
    "# #         \n",
    "#         return torch.nn.Softmax()(out)\n",
    "\n",
    "# embedding = nn.Embedding.from_pretrained(embed_tensor, freeze=True)\n",
    "# # vocab_size = len(vocab)\n",
    "# model = ToneTagsRNN(embedding=embedding)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.643443Z",
     "iopub.status.idle": "2024-05-06T00:05:43.643744Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.643596Z",
     "shell.execute_reply": "2024-05-06T00:05:43.643608Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.422099Z",
     "start_time": "2024-05-06T21:13:15.417066Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": "## Experiments",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-5,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset_clean\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader_clean,testloader=test_dataloader_clean,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.645061Z",
     "iopub.status.idle": "2024-05-06T00:05:43.645390Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.645226Z",
     "shell.execute_reply": "2024-05-06T00:05:43.645239Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.427631Z",
     "start_time": "2024-05-06T21:13:15.423099Z"
    }
   },
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-3,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset2\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader,testloader=test_dataloader,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.646617Z",
     "iopub.status.idle": "2024-05-06T00:05:43.647070Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.646824Z",
     "shell.execute_reply": "2024-05-06T00:05:43.646842Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.432698Z",
     "start_time": "2024-05-06T21:13:15.428632Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": "# configs = {\"epoch\":20,\"optLr\":1e-3,\"optM\":0,\"model\":\"RNN_2\",\"dataset\":\"dataset2\",\"loss\": \"CrossEntropy\"}\n# # configs = {\"epoch\":20,\"opt\":\"Adam\",\"betas\":(0.9,0.99),\"optLr\":5e-4,\"optM\":0,\"model\":\"ViT\",\"dataset\":\"noChange\",\"loss\": \"BCELoss\"}\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n# opt = torch.optim.Adam(params=model.parameters(),lr=configs['optLr'])\n# loss = torch.nn.CrossEntropyLoss()\n\n# wandb.init(config=configs,\n#            project=\"AML\", \n#            name='RNN_2')\n\n# train(epoch=configs['epoch'],trainloader=train_dataloader,testloader=test_dataloader,model=model,loss=loss,opt=opt)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.648456Z",
     "iopub.status.idle": "2024-05-06T00:05:43.648756Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.648608Z",
     "shell.execute_reply": "2024-05-06T00:05:43.648620Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.437911Z",
     "start_time": "2024-05-06T21:13:15.433698Z"
    }
   },
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": "## Tuning",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "datasets_list = {\"clean_corrected_wsd_2\": clean_corrected_wsd2_creator,\n",
    "                 \"wsd2\": wsd2_creator,\n",
    "                 }\n",
    "embedings_list = {\n",
    "    # \"6B\":get_glove_6b,\n",
    "    # \"840B\":get_glove_42b,\n",
    "    \"twitter\": get_glove_twitter\n",
    "}\n",
    "models_list = {\n",
    "    \"RNN\": ToneTagsRNN,\n",
    "    \"After_Model_RNN\": ToneTags_After_Model_RNN,\n",
    "    # \"LSTM\":ToneTagsLSTM,\n",
    "    \"After_Model_LSTM\": ToneTags_After_Model_LSTM\n",
    "}\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.649855Z",
     "iopub.status.idle": "2024-05-06T00:05:43.650187Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.650026Z",
     "shell.execute_reply": "2024-05-06T00:05:43.650040Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:13:15.443981Z",
     "start_time": "2024-05-06T21:13:15.438912Z"
    }
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": [
    "configs1 = {\n",
    "    \"epoch\": {'value': 10},\n",
    "    \"optimizer\": {'value': 'adam'},\n",
    "\n",
    "    \"betas\": {'value': (0.9, 0.99)},\n",
    "\n",
    "    \"optLr\": {'values': [1e-5, 1e-4]},\n",
    "\n",
    "    \"dataset\": {'values': list(datasets_list.keys())},\n",
    "    \"model\": {'values': list(models_list.keys())},\n",
    "    \"embeding\": {'values': list(embedings_list.keys())},\n",
    "    \"loss\": {'value': \"CrossEntropy\"}\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# # opt = torch.optim.SGD(params=model.parameters(),lr=configs['optLr'])\n",
    "# \n",
    "\n",
    "\n",
    "def run_experiment(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        global vocab_collate_fn\n",
    "        config = wandb.config\n",
    "\n",
    "        embeding, vocab, e_size = embedings_list[config['embeding']]()\n",
    "        vocab_collate_fn = vocab\n",
    "\n",
    "        model = models_list[config['model']]\n",
    "        model = model(embeding, vocab_size=e_size)\n",
    "\n",
    "        opt = torch.optim.Adam(params=model.parameters(), lr=config['optLr'])\n",
    "\n",
    "        loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_loader, test_loader = datasets_list[config['dataset']](vocab)\n",
    "\n",
    "        train(epoch=config['epoch'], trainloader=train_loader, testloader=test_loader, model=model, loss=loss, opt=opt)\n",
    "\n",
    "        del train_loader\n",
    "        del test_loader\n",
    "        del embeding\n",
    "        del vocab\n",
    "\n",
    "        vocab_collate_fn = None\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "}\n",
    "sweep_config['metric'] = {'name': 'loss/train',\n",
    "                          'goal': 'minimize'\n",
    "                          }\n",
    "sweep_config['parameters'] = configs1\n",
    "sweep_id1 = wandb.sweep(sweep_config, project=\"AML\")\n",
    "# sweep_config['parameters'] = configs2\n",
    "# sweep_id2 = wandb.sweep(sweep_config, project=\"kontur\")\n",
    "\n",
    "wandb.agent(sweep_id1, run_experiment)\n",
    "# wandb.agent(sweep_id2, run_experiment)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-06T00:05:43.651261Z",
     "iopub.status.idle": "2024-05-06T00:05:43.651558Z",
     "shell.execute_reply.started": "2024-05-06T00:05:43.651408Z",
     "shell.execute_reply": "2024-05-06T00:05:43.651420Z"
    },
    "trusted": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-06T21:13:15.444981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: g9lc91w7\n",
      "Sweep URL: https://wandb.ai/my_own_opt/AML/sweeps/g9lc91w7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: inor95dt with config:\n",
      "wandb: \tbetas: [0.9, 0.99]\n",
      "wandb: \tdataset: clean_corrected_wsd_2\n",
      "wandb: \tembeding: twitter\n",
      "wandb: \tepoch: 10\n",
      "wandb: \tloss: CrossEntropy\n",
      "wandb: \tmodel: RNN\n",
      "wandb: \toptLr: 1e-05\n",
      "wandb: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\_Inno\\AdditionalReps\\advanced-machine-learning-project-iu-2024\\notebooks\\wandb\\run-20240507_021318-inor95dt</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/my_own_opt/AML/runs/inor95dt' target=\"_blank\">rose-sweep-1</a></strong> to <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/my_own_opt/AML/sweeps/g9lc91w7' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/g9lc91w7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/my_own_opt/AML' target=\"_blank\">https://wandb.ai/my_own_opt/AML</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View sweep at <a href='https://wandb.ai/my_own_opt/AML/sweeps/g9lc91w7' target=\"_blank\">https://wandb.ai/my_own_opt/AML/sweeps/g9lc91w7</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/my_own_opt/AML/runs/inor95dt' target=\"_blank\">https://wandb.ai/my_own_opt/AML/runs/inor95dt</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "print('Hello world')",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
